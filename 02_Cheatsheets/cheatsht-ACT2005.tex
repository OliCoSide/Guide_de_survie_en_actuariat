% Template pour faire aide-mémoire
\documentclass[10pt, french]{article}

%% -----------------------------
%% Préambule
%% -----------------------------
\input{cheatsht-preamble-general.tex}
%% -----------------------------
%% Variable definition
%% -----------------------------
\def\cours{Mathématiques actuarielles IARD I}
\def\sigle{ACT-2005}
%% -----------------------------
%% Colour setup for sections
%% -----------------------------
\def\SectionColor{red!80!white}
\def\SubSectionColor{red!30!black}
\def\SubSubSectionColor{red!30!black}
%% -----------------------------
%% Début du document
%% -----------------------------
\begin{document}

\begin{center}
	\textsc{\Large Contributeurs}\\[0.5cm] 
\end{center}
\input{contributeurs/contrib-ACT2005}

\newpage

\raggedcolumns
\small
\begin{multicols*}{3} % Nombre de colonnes (peut être changé plus tard.)

\setcounter{section}{2}
\section{Estimation non-paramétrique}
\subsection*{Moments à savoir}
\begin{align*}
\mu_k^{\prime} 	& = \esp{X^k} &
\mu_k			& = \esp{(X-\mu)^k} \\
CV				& = \frac{\sigma}{\mu} \\
\text{Skewness: } \gamma			& = \frac{\mu_3}{\sigma^3}  &
\text{Kurtosis: } \kappa			& = \frac{\mu_4}{\sigma^4} \\
\end{align*}


\tikzset{every picture/.style={line width=0.75pt}} %set default line width to 0.75pt        

\begin{tikzpicture}[x=0.75pt,y=0.75pt,yscale=-1,xscale=1]
%uncomment if require: \path (0,300); %set diagram left start at 0, and has height of 300

%Curve Lines [id:da2688874623271533] 
\draw [color={rgb, 255:red, 208; green, 2; blue, 27 }  ,draw opacity=1 ][fill={rgb, 255:red, 208; green, 2; blue, 27 }  ,fill opacity=0.39 ][line width=3]  [dash pattern={on 7.88pt off 4.5pt}]  (80.5,138.67) .. controls (132.5,138.67) and (117.5,43.67) .. (151.5,43.67) .. controls (185.5,43.67) and (178.5,139.67) .. (229.5,138.67) ;


%Curve Lines [id:da9147539678395264] 
\draw [color={rgb, 255:red, 126; green, 211; blue, 33 }  ,draw opacity=1 ][fill={rgb, 255:red, 184; green, 233; blue, 134 }  ,fill opacity=0.64 ][line width=3]    (49,139) .. controls (163.5,131.67) and (184.83,55) .. (201.5,42.67) .. controls (218.17,30.33) and (212.5,140) .. (263.5,139) ;


%Curve Lines [id:da8124483083453555] 
\draw [color={rgb, 255:red, 74; green, 144; blue, 226 }  ,draw opacity=1 ][fill={rgb, 255:red, 74; green, 144; blue, 226 }  ,fill opacity=0.6 ][line width=3]    (49,139) .. controls (87.5,139.67) and (80.17,24.33) .. (98.5,43.67) .. controls (116.83,63) and (152.5,129.67) .. (263.5,139) ;


%Straight Lines [id:da7586443312018019] 
\draw [line width=2.25]    (49,139) -- (263.5,139) ;



%Straight Lines [id:da09355877210927566] 
\draw [line width=2.25]    (34.17,287) -- (322.17,287) ;


%Curve Lines [id:da18622021578279613] 
\draw [color={rgb, 255:red, 245; green, 166; blue, 35 }  ,draw opacity=1 ][line width=3]    (219.17,255.33) .. controls (252.17,270) and (304.17,273) .. (319.17,271.33) ;


%Curve Lines [id:da37988280307937217] 
\draw [color={rgb, 255:red, 0; green, 166; blue, 35 }  ,draw opacity=1 ][line width=3]    (219.17,254.33) .. controls (235.17,285) and (300.17,282) .. (318.17,282.33) ;


%Straight Lines [id:da5412137305076621] 
\draw [line width=2.25]    (159.17,169) -- (159.17,286) ;


%Curve Lines [id:da11948970250620294] 
\draw [color={rgb, 255:red, 208; green, 2; blue, 27 }  ,draw opacity=1 ][line width=3]    (35.17,276) .. controls (61.17,276) and (106.17,272) .. (121.17,244) .. controls (136.04,220.92) and (143.5,190.67) .. (160.5,190.67) .. controls (177.5,190.67) and (185.87,234.17) .. (219.17,255.33) .. controls (249.17,279) and (309.17,277) .. (319.17,277) ;



% Text Node
\draw (151,15) node [scale=0.8,color={rgb, 255:red, 208; green, 2; blue, 27 }  ,opacity=1 ] [align=left] {No Skewness\\\textit{(symmétrique)}};
% Text Node
\draw (252,40) node [scale=0.8,color={rgb, 255:red, 65; green, 117; blue, 5 }  ,opacity=1 ] [align=left] {Negative Skewness\\\textit{ \ \ \ \ (right-modal)}};
% Text Node
\draw (54,40) node [scale=0.8,color={rgb, 255:red, 65; green, 117; blue, 5 }  ,opacity=1 ] [align=left] {\textcolor[rgb]{0.29,0.56,0.89}{Positive Skewness}\\\textit{\textcolor[rgb]{0.29,0.56,0.89}{ \ \ \ \ (left-modal)}}};
% Text Node
\draw (230,206) node [scale=0.8,color={rgb, 255:red, 65; green, 117; blue, 5 }  ,opacity=1 ] [align=left] {$\displaystyle  \begin{array}{{>{\displaystyle}l}}
\textcolor[rgb]{0.96,0.65,0.14}{k\  >3}\\
\textcolor[rgb]{0.82,0.01,0.11}{k\ =3}\\
\textcolor[rgb]{0.0,0.65,0.14}{k\ < 3}
\end{array}$};

\end{tikzpicture}

\subsection*{3 critères pour évaluer les queues de distributions}

\begin{enumerate}

\item La loi avec le moins de moments a la queue la plus lourde.
\item Première à diverger du quotient des distributions a la queue la plus lourde.
\[\lim_{x \to \infty} \frac{f_{X_1}(x)}{f_{X_2}(x)}\]
\item Si la fonction hasard $h(x) = \frac{f_X(x)}{S_X(x)}$ est croissante alors la queue est fine, sinon elle est lourde.
\[
\begin{matrix}
	h_X'(x) < 0 & \text{queue lourde} \\
	h_X'(x) > 0 & \text{queue fine} \\
\end{matrix}
\]
\end{enumerate}


\subsection*{Quantités des distributions à connaître}

\begin{itemize}
\item[$Y^P$ : ] 
	\textbf{Excess loss}, alias \textbf{left truncated} and \textbf{shifted} variable. \\
	On interprete comme le \textit{montant de perte} en \textit{excès d'un déductible d} sachant que la perte est au delà de ce montant.


\item[$Y^L$ : ] 
	\textbf{Left censored} and \textbf{shifted} variable. \\ 
	Elle est défini comme étant 0 pour toutes les pertes inférieures à d, alors que l'excès-moyen n'est simplement pas défini dans ces cas. \\
	Donc, celle-ci a une masse à 0.


\item[$Y$ : ] 
	\textbf{Limited loss}, alias \textbf{right censored} variable. \\ 
	


	\begin{description}
		\item[\textbf{shifted} :] d est soustrait des valeurs restantes. \\
		On peut visualiser le déplacement de la courbe de densité à la gauche.
		\item[\textbf{left truncated} :] Toutes valeurs inférieures à d ne sont pas observées.			
		\item[\textbf{left censored} :] Toutes valeurs inférieures à d sont égale à 0.
		\item[\textbf{right censored} :] Toutes valeurs supérieures à u sont égale à u.
	\end{description}	
	\textbf{\textit{Pour exemple}}, lorsqu'il y a une limite sur une police d'assurance les valeurs au-delà ne sont pas typiquement inscrites à leur vrai montant, mais plutôt comme la limite $u$.
\end{itemize}


\begin{itemize}
\item[] \textbf{Moments}
\begin{align*}
	\esp{Y^P} &= \esp{X-d | X \geq d} = \frac{\int_{d}^{\infty} S_X(x)}{S_X(d)} = e_X(d) \\
	\esp{Y^L} &= \esp{(X - d)_+} = \int_{d}^{\infty} (x - d) f_X(x) dx \\
	\esp{Y} &= E[X \wedge d] = \int_0^d f_X(x) dx \Leftrightarrow \int_0^d S_X(x) dx
\end{align*}

%\item[] \textbf{Définitions des variables}
%\begin{align*}
%Y^P 	&= ( X - d | X > d ) 
%	&= 
%	\left\{
%		\begin{array}{ll}
%			\text{undefined}, 	& X \leq d \\
%			X - d, 				& X > d
%		\end{array}
%	\right. \\
%Y^L 	&= ( X - d )_+ 
%	&= 
%	\left\{
%		\begin{array}{ll}
%			0, 		& X \leq d \\
%			X - d, 	& X > d
%		\end{array}
%	\right. \\
%Y 	&= (X \wedge u)
%	&= 
%	\left\{
%		\begin{array}{ll}
%			X, & X < u \\
%			u, & X \geq u
%		\end{array}
%	\right.
%\end{align*}
\end{itemize}

\setcounter{section}{7}
\columnbreak
\section{Fréquence et sévérité avec modifications aux contrats}

\subsubsection*{Déductible ordinaire}

\paragraph{L'assureur paye tout montant en excédent du montant d.}
%\setlength{\abovedisplayskip}{-20pt}
%\setlength{\belowdisplayskip}{20pt}
\begin{align*}
Y^{(L\textcolor{blue}{|P)}}_{(O)} &= (X-d)_+ = 
	\begin{cases}
		(0 {\color{blue}{| \text{non-défini})}}		& , X \leq d \\
		X - d	& , X > d \\
	\end{cases} 
%	\\
%Y^P &= (X-d)_+ = 
%	\begin{cases}
%		\text{Non-défini}	& , X \leq d \\
%		X - d				& , X > d \\
%	\end{cases}
\end{align*}

\subsubsection*{Déductible franchise}
\paragraph{L'assureur paye l'entièreté des coûts pour toute perte qui surpasse le montant d.\\ \textit{Pour éviter les petites réclamations}}
\begin{align*}
Y^{(L\textcolor{blue}{|P)}}_{\color{red}{(F)}} &= (X-d)_+ = 
	\begin{cases}
		(0 {\color{blue}{| \text{non-défini})}}		& , X \leq d \\
		X		& , X > d \\
	\end{cases} 
%	\\
%Y^P &= (X-d)_+ = 
%	\begin{cases}
%		\text{Non-défini}	& , X \leq d \\
%		X 					& , X > d \\
%	\end{cases}
\end{align*}

\subsubsection*{Moments}
\begin{align*}
E[Y_{(O\textcolor{red}{|F)}}^{(L\textcolor{blue}{|P)}}] &= \frac{E[X] - E[X \wedge d] + \textcolor{red}{d S_X(d)} }{\textcolor{blue}{S_X(d)}} \\
\end{align*}
%Où (L|P) et (O|F) est à être interprété en REGEX. \\
%C'est soit per loss (L) ou \textcolor{blue}{per payment (P)} \\
%C'est soit un déductible ordinaire (O) ou \textcolor{red}{avec franchise (F)}.
De plus, on note que:
\begin{align*}
E[Y_{(O)}^{(\textcolor{blue}{P)}}] &= e_X(d) \\
E[Y_{(O)}^{(L)}] &= \pi_X(d)
\end{align*}

\subsubsection*{Fonctions}
\begin{align*}
f_{Y^{(L\textcolor{blue}{|P)}}_{(O)}} &= \frac{f_X(y+d)}{\textcolor{blue}{S_X(d)}} &
h_{Y^{(L\textcolor{blue}{|P)}}_{(O)}} &= h_X(y+d) \\
S_{Y^{(L\textcolor{blue}{|P)}}_{(O)}} &= \frac{S_X(y+d)}{\textcolor{blue}{S_X(d)}} &
F_{Y^{(L\textcolor{blue}{|P)}}_{(O)}} &= \frac{F_X(y+d) \textcolor{blue}{- F_X(d)}}{\textcolor{blue}{S_X(d)}} \\
\end{align*}


\subsection*{LER et inflation du déductible ordinaire}
%\subsubsection*{}
Le LER nous donne le pourcentage de perte qu'on ne paie pas grâce au déductible
\begin{align*}
	LER 	 &= \frac{\esp{X} - \esp{(X-u)_+}}{\esp{X}} \\
	     &= \frac{\esp{X \wedge u}}{\esp{X}} 
\end{align*}
Soit $X^I = (1 + r) X$
\begin{align*}
	E[{X^I} \wedge u]	 &= (1 + r) E[X \wedge \frac{u}{1 + r}] \\
	f_{X^I}(x) &= \frac{f_X\left(\frac{y}{1 + r}\right)}{1 + r} \\
	F_{X^I}(x) &= F_X\left(\frac{y}{1 + r}\right)
\end{align*}

\subsection*{Limite de police}
\subsubsection*{L'assureur paye un maximum de $u$}

\begin{align*}
Y 	&= (X \wedge u)
	= 
	\left\{
		\begin{array}{ll}
			X, & X < u \\
			u, & X \geq u
		\end{array}
	\right. \\
f_Y(y) &=
		\left\{
			\begin{array}{ll}
				f_X(y), & y < u \\
				S_X(u), & y = u
			\end{array}
		\right. \\
F_Y(y) &=
		\left\{
			\begin{array}{ll}
				F_X(y), & y \leq u \\
				1, & y > u
			\end{array}
		\right. 
\end{align*}

\subsection*{Coassurance}
\subsubsection*{L'assureur paye une fraction, $\alpha$, de la perte.}

Si la coassurance est la seule modification, alors nous obtenons $Y = \alpha X$. \\
\textit{L'impact sur les fonctions est le même qu'avec de l'inflation}.

\subsection*{Formule récapitulative}
\paragraph{Lorsque les 4 items sont présent (déductible \textit{ordinaire}, limite, inflation et coassurance.}

\begin{align*}
Y^{(L\textcolor{blue}{|P)}}_{(O)} &= 
\begin{cases}
(0 {\color{blue}{| \text{Non-défini})}}		& ,\ x  < \frac{d}{1+r} \\
\alpha \Big( (1+r) x - d \Big)	& ,\ \frac{d}{1+r} \leq x < \frac{u}{1+r} \\
\alpha (u-d)		& ,\ x \geq \frac{u}{1+r} 
\\
\end{cases}
\\
%Y^P = 
%\begin{cases}
%\text{Non-défini}		& ,\ x  < \frac{d}{1+r} \\
%\alpha \Big( (1+r) x - d \Big)	& ,\ \frac{d}{1+r} \leq x < \frac{u}{1+r} \\
%\alpha (u-d)		& ,\ x \geq \frac{u}{1+r} 
%\\
%\end{cases}
\esp{Y^{(L\textcolor{blue}{|P)}}_{(O)}} &= \frac{\alpha (1+r) \left( \esp{X \wedge \frac{u}{1+r}} - \esp{X \wedge \frac{d}{1+r}}   \right)}{{\color{blue}{S_X \left( \frac{d}{1+r} \right)}}} 
%\\
%\esp{Y^P} &= \frac{\esp{Y^L}}{S_X \left( \frac{d}{1+r} \right)}
\end{align*}

\setcounter{section}{13}
\columnbreak
\section{Estimation non-paramétrique des fonctions de répartition et de survie}

\subsection*{Distribution empirique avec données complètes}

I.C. au niveau $1 - \alpha$ de $F(x) \in \left[F_n(x) \pm z_{1 - \frac{\alpha}{2}} \sqrt{\widehat{V}(F_n(x))} \right]$
\begin{enumerate}
	\item[$y_j$ : ] la j-ème des $k$ valeurs unique de l'échantillon de n ($k \le n$).\\
	$y_1 < y_2 < \dots < y_k$
	\item[$s_j$ : ] Nombre de fois que l'observation $y_j$ est observé dans l'échantillon.\\
	$\sum_{j = 1}^{k}s_j = n$
	\item[$r_j$ : ] Nombre d'observations $\ge y_j$. \\
	$\sum_{i = j}^{k}s_i = r_j$
\end{enumerate}

\begin{align*}
F_n(x) &= \frac{1}{n} \sum\limits_{j=1}^n I_{\{ x_j \leq x\}} \\
f_n(x) &= \frac{1}{n} \sum\limits_{j=1}^n I_{\{ x_j = x\}}  \\
 n F_n&(x)  \sim \text{bin}(n, F(x))\\
E[F_n(x)] &
%		= \frac{n F_n(x)}{n} \\
		= F_n(x)\\
\widehat{Var}[F_n(x)] &
%= \frac{n F_n(x)(1 - F)n(x)}{n^2} 
= \frac{F_n(x)(1 - F_n(x))}{n}  \\
%\widehat{Var}[S_n(x)] &= \frac{S_n(x)(1 - S_n(x))}{n} \\
F_n(x) &= 
\left\{
	\begin{array}{ll}
		0,  &  x < y_1 \\
        1 - \frac{r_j}{n}, &  y_{j-1} \leq x < y_j \\
        1, & x > y_k 
	\end{array}
\right. \\
&&\forall j=2,...,k
\end{align*}

\subsection*{Distribution empirique avec données groupées}
\subsubsection*{Fonction OGIVE}
% Voir fonction OGIVE du packetage actuar en R.
\begin{itemize}
    \item Dans certains contextes, on a $n$ données qui sont groupées en intervalles et la fonction OGIVE permet d'interpoler entre 2 points $c_{j - 1}$ et $c_j$.
    \item On défini $n_j$ comme étant le nombre d'observations entre $c_{j - 1}$ et $c_{j}$.
    \item Soit $x$ tel que
    \begin{align*}
    		c_{j - 1} \le &\ x \le c_j \\
    		F_{n	}(c_{j - 1}) \le &\ F_{n}(x) \le F_{n}(c_{j}) 
    \end{align*}
    Alors 
    \begin{align*}
		F_{n}^{\text{OGIVE}}(x) &= \alpha F_{n}(c_{j - 1}) + (1 - \alpha) F_{n}(c_{j}) \\
		&= \frac{c_{j} - x}{c_{j} - c_{j - 1}} F_{n}(c_{j - 1}) + \frac{x - c_{j - 1}}{c_{j} - c_{j - 1}} F_{n}(c_{j}) \\
       	\text{où } &\ F_{n}(c_j) = \frac{\sum_{i = 1}^{j} n_{i}}{n} \\
       	f_n(x) &= \frac{F_{n}(c_{j}) - F_{n}(c_{j - 1})}{c_{j} - c_{j - 1}} \Leftrightarrow \frac{n_j}{n(c_{j} - c_{j - 1})} \\
    \end{align*}
\end{itemize}

\subsection*{Estimations empirique avec données censurées à droite}

\begin{enumerate}
	\item [] On représente les données censurées avec:
	\item[$b_{i}$ : ] Nombre d'observations censurées à la droite dans l'intervalle $[y_{i}, y_{i + 1}) \ \forall i = 1, 2, \dots, k - 1$
%	$b_{k} = r_{k} - s_{k}$
	\item[] De plus, on interprète les valeurs définies plus haut.
	\item[$s_i$ : ] Nombre de décès au temps $i$.
	\item[$r_i$ : ] Le nombre \textit{\textbf{à risque}} à l'observation $y_{i}$.
\begin{align*}
	r_{i} = 
		\begin{cases}
			n, & i = 1 \\
			r_{i - 1} - s_{i - 1} - b_{i - 1}, & i = 2, 3, \dots, k + 1
		\end{cases}
\end{align*}
\end{enumerate}

%\item[] Par la suite, on peut interpréter la fonction de survie comme une probabilité conditionnelle puisque $S(t_0) = 1$.
On peut interpréter la fonction de survie comme une \textbf{probabilité conditionnelle}.
\begin{align*}
	S(t) &= \frac{S(t_1)}{S(t_0)} \times \frac{S(t_2)}{S(t_1)} \times \dots \times \frac{S(t)}{S(t-1)} \\
	&\Leftrightarrow p_{1} \times p_{2} \times \dots \times p_{t} = \prod_{j \le t} p_{j} \\
	\text{où } p_{t} &= P(T > t | T > t - 1) \\
%	\text{et } q_{t} &= P(T < t | T > t - 1)
\end{align*}

On peut donc estimer $p_{j}$ par:
\begin{align*}
		\hat{p}_{j} &=
%		 1 - \hat{q}_{j} = 1 - \hat{\lambda}_{j} = 
		 1 - \frac{S_{j}}{r_{j}} \\
		\text{où } S_j &\sim \text{Bin}(r_j, q_j) 
\end{align*}

Ceci correspond donc à l'estimateur de \textbf{Kaplan-Meier}:
\begin{formula}{Estimateur Kaplan-Meier de la fonction de survie empirique}
\begin{align*}
	S_{m}(t) &= \prod\limits_{j \le t} \left( 1 - \frac{S_j}{r_j} \right) \\		
\end{align*}
\end{formula}

%Pour trouver la variance, nous utilisons la \textbf{méthode Delta} :
%\begin{align*}
%	\text{Var}\big(g(\widehat{\theta})\big) 
%	&= \big(g'(\widehat{\theta}_{0})\big)^2 \text{Var}(\widehat{\theta})
%\end{align*}
%Pour ensuite obtenir:
%\begin{align*}
%	\text{Var}(S_n(t)) 
%	&= \big( S_n(t) \big)^2 \sum_{j \le t}\frac{q_j}{r_j p_j} 
%\end{align*}

La \textbf{Formule de Greenwood} estime la variance de la fonction de survie \textbf{Kaplan-Meier}:
\begin{formula}{Formule de Greenwood}
	\begin{align*}	
		\widehat{V}\big(S_{m}(t)\big) &= \big(S_{m}(t)\big)^2 \sum_{j \le t} \frac{S_j}{r_j(r_j - S_j)} 
	\end{align*}
\end{formula}
%\end{enumerate}

%\subsubsection*{Estimateur \textbf{Nelson-Aalen} de la \textbf{\textit{cumulative hazard rate function}}}


La \textbf{\textit{cumulative hazard rate function}} est estimée par l'estimateur \textbf{Nelson-\AA alen}:
\begin{formula}{Estimateur Nelson-\AA alen du cumulative hazard rate function}
\begin{align*}
	\widehat{H}(t) &= 
	\sum_{j \le t}  \frac{S_{j}}{r_{j}}	
\end{align*}
\end{formula}
L'estimateur de la fonction de survie peut ensuite être déduit:
\begin{align*}
		\widehat{S}(t) &= 
		e^{-\widehat{H}(t)}
\end{align*}	
%La variance de la \textbf{\textit{cumulative hazard rate function}} est représentée comme suit:
%	\begin{align*}	
%		V(\widehat{H}(t)) &= \sum_{j \le t} V\left( \frac{S_j}{r_j} \right) = \frac{q_j p_j}{r_j}
%	\end{align*}
La variance de l'estimateur Nelson-\AA alen est estimée par la \textbf{formule de Klein}:
\begin{formula}{Formule de Klein}
\begin{align*}	
		\widehat{V}\big(\widehat{H}(t)\big) &= 
%		\sum_{j \le t} \frac{\widehat{q}_j \widehat{p}_j}{r_j} =
		\sum_{j \le t} \frac{S_j (r_j - S_j)}{r_j^3}  
	\end{align*}
\end{formula}

\begin{formula}{Intervalles de confiance}
\begin{align*}
	H(t) &\in \left[ \widehat{H}(t) \pm z_{\alpha/2} \sqrt{\widehat{\text{V}}(\widehat{H}(t))} \right] \\	
	S(t) &\in \left[ S_m(t) \pm z_{\alpha/2} \sqrt{\widehat{\text{V}}\big(S_m(t)\big)} \right] \\
\end{align*}
\end{formula}

\textbf{Méthode d'efron}: Poser que $S_m(y) = 0$ $\forall y \ge y_{\text{max}}$.

Il est bon de noter que le résulat pour la variance de XXX à été obtenu avec la \textbf{méthode de Delta} qui consiste aux deux premiers termes de l'expansion Taylor:
\begin{formula}{méthode de Delta}
\begin{align*}
	g(\hat\theta)
	&\approx	 g(\theta) + g'(\theta) (\hat\theta - \theta)
\end{align*}
\end{formula}

\setcounter{section}{5}

\columnbreak
\section{Création de nouvelles lois}

\begin{algo}{Multiplication par une constante}
Ceci équivaut à appliquer l'inflation uniformément pour tous les niveaux de pertes et est donc un \textbf{changement d'échelle}.

Soit $Y = \theta X$, alors:

\begin{align*}
	F_Y(y)
	&=	\Pr(Y \leq y)	
	=	\Pr(\theta X \leq y)	\\
	&=	\Pr\left(X \leq \frac{y}{\theta}\right)	
	=	F_X\left(\frac{y}{\theta}\right)	\\
\Rightarrow	f_Y(y)
	&=	\frac{1}{\theta} f_X\left(\frac{y}{\theta}\right)
\end{align*}

On déduit donc que le paramètre $\theta > 0$ est un \textit{paramètre d'échelle} pour la variable aléatoire $Y$.

\end{algo}

\begin{algo}{Élévation à une puissance}

Soit la variable aléatoire de pertes $X$ et $Y = X^{\frac{1}{\tau}}$, alors:

\begin{align*}
	F_Y(y)
	&=	\Pr(Y \leq y)	
	=	\Pr(X^{\frac{1}{\tau}} \leq y)	\\
	&=	\Pr\left(X \leq y^{\tau}\right)	
	=	F_X\left(y^{\tau}\right)	\\
\Rightarrow	f_Y(y)
	&=	\shortminus \tau y^{\tau - 1} f_X\left(y^{\tau}\right)
\end{align*}

Et on note la terminologie suivante:

\begin{tabular}{|l | l |}
\hline
	$\tau > 0$	&	$Y$ est une \textit{\textbf{transformation}} de $X$	\\
	$\tau = -1$	&	$Y$ est \textit{\textbf{l'inverse}} de $X$	\\
	$\tau < 0$	&	$Y$ est une \textit{\textbf{transformation inverse}} de $X$	\\	\hline
\end{tabular}

\end{algo}

\begin{algo}{Exponentielle}

Soit la variable aléatoire de pertes $X$ et $Y = \te{X}$, alors:

\begin{align*}
	F_Y(y)
	&=	\Pr(Y \leq y)	
	=	\Pr(\e{X} \leq y)	\\
	&=	\Pr\left(X \leq \ln y \right)	
	=	F_X\left(\ln y \right)	\\
\Rightarrow	f_Y(y)
	&=	\frac{1}{y} f_X\left(\ln y \right), y > 0
\end{align*}

On dit donc que $Y$ est la \textit{log-loi} où $\ln Y = X$ est la loi.

\end{algo}

\begin{algo}{Mélange}

\end{algo}

% pas couvert dans le cours mais dans l'exam apparament
%\begin{algo}{Raccordement de distributions (splicing)}
%
%\end{algo}

%\begin{algo}{Frailty models}
%
%\end{algo}

\setcounter{section}{8}

\columnbreak
\section{Fonction génératrice cumulante}
Soit la fonction génératrice des moments $M_X(t)$, telle que
\[M_X(t) = \esp{e^{tX}}\]
Alors, la fonction génératrice cumulante $K_X(t)$ est définie comme
\[K(t) = \ln M_X(t)\]
De plus, la fonction génératrice cumulante a les propriétés suivantes : 
\begin{align*}
K'(t) \eval_{t = 0} & =   \esp{X} \\
K''(t) \eval_{t=0} & = \variance{X} \\
\end{align*}

\setcounter{section}{9}
\columnbreak
\section{Frequentist estimation}
\subsection*{Méthode des moments}

Soit un échantillon aléatoire de taille $n$ (iid), on pose $\hat\mu_{k}' = \mu_{k}'$.

\begin{algo}{Estimateur par la méthode des moments}
Un estimateur par la méthode des moments de $\theta$ est alors toute solution des $p$ équations
\begin{equation*}
	\mu_{k}'(\theta) = \hat\mu_{k}', \quad	k = 1, 2, \dots, p
\end{equation*}
\end{algo}

La raison pour cet estimateur est que la distribution empirique aura les même $p$ premiers moments centrés à 0 que la distribution paramétrique.
 

Lorsque les données sont \textbf{censurées}, on pose $\hat\mu_{k}' = \text{E}[\min(X; u)^{k}]$.

Lorsque les données sont \textbf{tronquées}, on pose $\hat\mu_{k}' = \text{E}[X^{k} | X > d]$.


\subsection*{Méthode des percentiles}


Soit un échantillon aléatoire de taille $n$ (iid), on pose $\hat\pi_{g}(\theta) = \pi_{g}(\theta)$.

\begin{algo}{Estimation de $\theta$ par la méthode du \guillemotleft Percentile Matching \guillemotright}
L'estimation de $\theta$ est alors toute solution des $p$ équations:
\begin{equation*}
	F(\hat\pi_{g_{k}} | \theta)	=	g_{k}, \quad	k = 1, 2, \dots, p
\end{equation*}
\end{algo}

La raison pour cet estimateur est que le modèle produit aura $p$ pourcentiles qui vont \guillemotleft matcher \guillemotright les données.

Lorsque les données sont \textbf{censurées}, on doit s'assurer que les pourcentiles sont en dedans de la portion des données non-censurées.

Lorsque les données sont \textbf{tronquées}, on doit \guillemotleft matcher \guillemotright les pourcentiles aux pourcentiles de la distribution conditionnelle.

Il peut arriver que les pourcentiles de distributions ne soient pas unique, par exemple dans le cas de données discrètes lorsque le quantile recherché peut tomber entre 2 \emph{marches} de la fonction empirique, ou mal-définis.
Il est alors utile de définir une méthode d'interpolation des quantiles (bien qu'il n'en n'existe pas une officielle définitive).

Soit le \guillemotleft \textbf{smoothed empirical estimate} \guillemotright d'un pourcentile:

\begin{algo}{\guillemotleft smoothed empirical estimate \guillemotright}
On utilise les statistiques d'ordre de l'échantillon $x_{(1)} \le x_{(2)} \le \dots \le x_{(n)}$ pour l'interpolation suivant:
\begin{align*}
	\hat\pi_{\kappa}
	&=	(1 - h)x_{(j)} + h x_{(j + 1)}, \quad \text{ où }	
\end{align*}
\begin{align*}
	j
	&=	\lfloor (n + 1) \kappa \rfloor	&
	&\text{ et }	&
	h
	&=	(n + 1) \kappa - j
\end{align*}
\end{algo}


\subsection*{Méthode du maximum de vraisemblance (\emph{MLE})}

Nous cherchons à maximiser la probabilité d'observer les données.
Ceci est fait par la vraisemblance $\mathcal{L}(\theta; x)$ ou, puisque le logarithme ne change pas le maximum, la log-vraisemblance $\ell(\theta; x)$ où:

\begin{algo}{Maximum de vraisemblance}
\setlength{\mathindent}{-1cm}
\begin{align*}
	\mathcal{L}(\theta; x)
	&=	\prod_{i = 1}^{n}	f(x_{i}; \theta)	&
	&\text{et}	&
	\ell(\theta; x)
	&=	\sum_{i = 1}^{n} \ln	f(x_{i}; \theta)	
\end{align*}
\setlength{\mathindent}{1cm}
et l'\textbf{estimateur du maximum de vraisemblance} de $\bm\theta$ est celui qui maximise la fonction de vraisemblance.
\end{algo}
Cependant, il peut être pratique de généraliser cette fonction de vraisemblance pour les cas de données censurées ou tronquées.

Soit un ensemble de données comportant n événements $A_{1}, \dots, A_{n}$ avec $A_{j}$ étant tout ce qui fut observé pour la $j^{\text{e}}$ observation; c'est-à-dire que $A_{j}$ pourrait être une observation unique ou un intervalle (par exemple, dans le cas de données groupées).

De plus, un suppose que $A_{j}$ est une observation de la variable aléatoire $X_{j}$ et que les variables aléatoires $X_{1}, \dots, X_{n}$ ne doivent pas obligatoirement avoir la même distribution paramétrique; cependant, elles doivent tous dépendent du même vecteur paramétrique $\bm\theta$.
Finalement, comme dans les deux autres cas, les variables aléatoires sont supposées indépendantes.

\begin{align*}
	\mathcal{L}(\theta; x)
	&=	\prod_{j = 1}^{n}	\Pr(X_{j} \in A_{j} ; \theta)		
\end{align*}

Pour faire le lien avec la définition précédente, dans le cas où $A_{j}$ est un point unique et que la distribution est continue $\Pr(X_{j} \in A_{j} | \theta) = f(x_{i}; \theta)$.

\begin{algo}{Données modifiées}
Pour le cas de données groupées, les observations $c_{0} < c_{1} < \dots < c_{k}$ contiennent $n_{j}$ observations par intervalle $(c_{j - 1}, c_{j}]$.

Dans le cas des données censurées, on multiplie les fonctions de densité pour les données non-censurées et on remplace la densité pour la fonction de survie pour les données censurées; soit $n_{NC}$ le nombre de données non-censurées et $n_{C}$ le nombre censurées tel que $n = n_{NC} + n_{C}$.

La fonction de vraisemblance est donc:
\setlength{\mathindent}{-1cm}
\begin{align*}
	\mathcal{L}(\theta; x)
	&=	\prod_{j = 1}^{n}	\left[ F(c_{j}|\theta) - F(c_{j-1}|\theta)\right]^{n_{j}},	\;	\text{groupé}	\\
	&=	\left(\prod_{j = 1}^{n_{NC}}f(x_{i}; \theta) \right)	\left(\prod_{j = n_{NC} + 1}^{n} S(x_{i} ; \theta) \right),	\;	\text{censuré}	\\
	&=	\prod_{j = 1}^{n}	\frac{f(x_{i}; \theta)}{S(d ; \theta)},	\;	\text{tronqué}
\end{align*}
\setlength{\mathindent}{1cm}
\end{algo}

\subsection*{Variance des estimateurs et intervalle de confiance}

Soit, sous certaines conditions de régularité, l'\textbf{information de Fisher} $I(\theta)$:

\begin{formula}{Information de Fisher}
\begin{align*}
	I(\theta) 
	&= 	\text{E}\left[\left( \derivee{\theta} \ell(\theta) \right)^2\right]	\\
	&\Leftrightarrow	-\text{E}\left[\frac{\partial^2}{\partial \theta^2} \ell(\theta)\right]	\\
\end{align*}
La simplification (2ème équation) est pour le cas où les observations sont (iid) et ont donc tous la même fonction de log-vraisemblance.
\end{formula}

Si l'information n'est pas connue, on peut l'estimer avec \textbf{l'information observée} : 
\begin{formula}{Information de Fisher observée}
\begin{align*}
	\hat{I}(\hat{\theta}) 
	&= 	\sum_{i=1}^{n} 	\left( \derivee{\theta} \ln f(x_i ; \theta) \eval_{\theta = \hat{\theta}} \right)^2 	\\
	&= 	-\sum_{i=1}^{n}	\frac{\partial^2}{\partial \theta^2} \ln f(x_i ; \theta) \eval_{\theta = \hat{\theta}} 
\end{align*}
\end{formula}

\subsubsection*{Estimation de la variance de $\hat{\theta}$}
Ainsi, on peut calculer la variance de l'estimateur $\hat{\theta}_{MLE}$ tel que
\[
	\text{Var}(\hat{\theta})
	= 	I(\theta)^{-1}
\]

\subsubsection*{Intervalle de confiance pour $\hat{\theta}$}
Lorsque $n \to \infty$, $\hat{\theta} \sim N(\theta,	\variance{\hat{\theta}})$ on peut trouver un IC pour l'estimateur au seuil de $1 - \alpha$ : 
\[
	\theta 
	\in 	\Big[
		\hat{\theta} \pm z_{\alpha/2} \sqrt{\mathrm{Var}(\hat{\theta})} 
		\Big]
\]

\subsubsection*{Méthode delta pour estimer la variance d'une transformation de $\hat{\theta}$}
Lorsqu'on veut calculer la variance d'une autre quantité que le paramètre $\hat{\theta}$ lui-même, on peut utiliser la méthode Delta : 
\[
	\variance{h(\hat{\theta})}
	= 	\left( \derivee{\theta} h(\theta) \right)^2 \variance{\hat{\theta}}
\]
Dans un contexte multivarié, où $\bm{\hat{\theta}}$ est un vecteur d'estimateurs, alors on a
\begin{align*}
	\text{Var}\big(h(\hat{\theta})\big)	
	&= 	\bm{h}^{\top} I(\theta)^{-1} \bm{h}
\end{align*}
où $\bm{h}$ est le vecteur des dérivées partielle de $h(\theta)$ : 
\begin{align*}
	\bm{h}	
	&=	\begin{bmatrix}
			\derivee{\theta_1} h(\theta) \\
			\derivee{\theta_2} h(\theta) \\
			... \\
			\derivee{\theta_k} h(\theta) \\
		\end{bmatrix}
\end{align*}


\setcounter{section}{14}
\columnbreak
\section{Sélection de modèles}

Il est essentiel de ne pas oublier que peu importe le modèle sélectionné, il sera une \textbf{approximation} de la réalité; \guillemotleft all models are wrong, but some are more useful than others \guillemotright.

\subsection*{Chi-Square \emph{Goodness-of-fit}}

On veut valider que les prévisions du modèle ne sont pas trop différentes des valeurs empiriques observées. 
Alias, that the predictions of the model has a \textbf{good fit} to the empirical data with similar percentiles.

On valide alors l'adéquation d'un modèle avec $p$ variables explicatives et $n$ observations en calculant la quantité $X^2$ : 
\begin{algo}{Test d'adéquation du Khi-Carré}
\begin{align*}
	X^2 
	&= 	\frac{\sum_{j = 1}^{k} n(\hat{p}_j - p_{nj})^2 }{\hat{p}_j} 
	\sim	\chi^{2}_{k - p - 1}
\end{align*}
où 
\begin{enumerate}
	\item[$\hat{p}_j$:]	Probabilité (selon le modèle) d'observer une valeur dans la $j^{e}$ classe.
	\item[$p_{nj}$:]	Proportion empirique des observations dans la $i^{e}$ classe.
\end{enumerate}
\end{algo}


On peut récrire ce test sous la forme suivante:
\begin{algo}{Test d'adéquation du Khi-Carré (autre forme)}
On pose 
\begin{itemize}
	\item	$n_{j}$ est le nombre de données dans le groupe $(c_{j - 1}, c_{j}]$,
	\item	$j \in \{1, \dots, k \}$,
	\item	$k$ est le nombre de groupes et
	\item	$\sum_{j = 1}^{k}n_{j} = n$.
\end{itemize}

La statistique de test est donc:
\begin{align*}
	Q 
	&= 	\frac{\sum_{j = 1}^{k} (E_j - n_{j})^2 }{E_j} 
\end{align*}
où
\begin{itemize}
	\item	Asymptotiquement, $Q \sim	\chi^{2}_{k - p - 1}$ et 
	\item	$p$ est le nombre de paramètres estimés,
	\item	$E_{j} = n [F(c_{j}; \hat{\bm\theta}) - F(c_{j - 1}; \hat{\bm\theta})]$.
\end{itemize}
On rejète $H_{0}$ si $Q > \chi_{k - p - 1, \alpha}^{2}$.
\end{algo}

On peut également effectuer le test LRT pour valider l'adéquation du modèle.

\subsection*{Test du rapport de vraisemblance (\emph{LRT})}
On utilise la statistique du khi-carré pour comparer deux modèles; la question est si le modèle sous $H_{1}$ est une représentation de la population mieux ajustée que le modèle sous $H_{0}$. 
On note que le modèle sous $H_{1}$ doit être une simplification de celui sous $H_{0}$.

En bref, on test si le modèle réduit avec $\theta_0$ est une \emph{bonne} simplification du modèle complet en testant si la différence des log-vraisemblances est significative : 
\begin{algo}{Test du rapport de vraisemblance (LRT)}
\[
	T 
	= 		2 \left( \ell(\theta) - \ell(\theta_0) \right)
	\sim		\chi_{dl_1 - dl_0, 1 - \alpha}^2
\]
\end{algo}
où $dl_1$ est le nombre de paramètres non-fixés du modèle complet et $dl_0$ le nombre de paramètres non-fixés du modèle réduit. 

\textbf{On va rejeter $H_0$ si $T >\chi_{dl_1 - dl_0, 1-\alpha}^2 $ (test unilatéral)} et conclure que le modèle réduit n'est pas une bonne simplification du modèle complet.

\subsubsection*{Construction d'un intervalle de confiance par inversion du \emph{LRT}}
Si $\theta_0$ est un paramètre adéquat pour le modèle réduit, alors la statistique $T$ du \emph{LRT} ne dépassera pas le quantile théorique $\chi_{dl, 1- \alpha^2}$. 
Alors, on veut trouver $\hat{\theta}_0$ tel que
\[2 \left( \ell(\theta) - \ell(\theta_0) \right) \leq  \chi_{dl_1 - dl_0, 1-\alpha}^2\]
On trouvera une équation du genre $g(\theta) \leq 0$, où $g$ sera une fonction avec deux racines définies, qui correspondent aux bornes de l'intervalle de confiance pour les valeurs de $\hat{\theta}_0$ : 

\begin{center}
	\includegraphics[scale = 0.07]{src/Q13-57_visualisation.png}
\end{center}

\subsection*{Méthode de Delta multivariée}
\begin{definitionNOHFILL}[Méthode de Delta multivariée]
Soit la variable aléatoire multivariée de \textbf{dimension $k$} et de \textbf{taille d'échantillon $n$} $\bm{X_{n}} = [X_{1n}, \dots, X_{kn}]^{\top}$.

On pose:
\begin{enumerate}
	\item	$\bm{X_{n}}$ est asymptotiquement normale \textit{(multivariée)} de 
	\item	moyenne $\bm\theta$ et
	\item	matrice de covariance $\frac{\bm\Sigma}{n}$,
\end{enumerate}
où les paramètres $\bm\theta$ et $\bm\Sigma$ ne dépendent pas de la taille d'échantillon $n$. 

On note que puisque $\bm{X_{n}}$ est asymptotiquement normale, ils deviennent les paramètres de la normale multivariée.
\\
\hrule\hrulefill

Soit la fonction $\bm{G_{n}} = g(X_{1n}, \dots, X_{kn})$.

On pose:
\begin{enumerate}
	\item	$\bm{G_{n}}$ est également asymptotiquement normale \textit{(\textbf{pas} multivariée)} mais de 
	\item	moyenne g($\bm\theta$) et
	\item	\textbf{\textit{variance}} $\frac{\bm{A}^{\top}\bm\Sigma\bm{A}}{n}$,
\end{enumerate}
où $\bm{A}$ est le gradient (c.-à-d., le vecteur des k premières dérivées) de $g(\bm\theta)$ évalué aux vrais paramètres $\bm\theta$ de $\bm{X_{n}}$; $\bm{A} = \left[\deriv{\theta_{1}}g, \dots, \deriv{\theta_{k}}g\right]^{\top} \bigg|_{\bm\theta}$.
\\
\hrule\hrulefill

Alors, on obtient:
\begin{formula}{Variance estimée méthode de Delta multivariée}
\begin{align*}
	\widehat{\text{Var}}(\hat{\bm\theta})
	&=	\frac{\hat{\bm{A}}^{\top} \hat{\bm\Sigma} \hat{\bm{A}}}{n}
\end{align*}
\end{formula}
\end{definitionNOHFILL}

\begin{examplebox}{Exemple avec une lognormale}
Puisque ce concept est très théorique et difficile à conceptualiser, nous jugeons pertinent d'inclure un exemple.
\\\hrulefill

On veut l'estimateur de la moyenne d'une distribution log-normale où:
\begin{equation*}
	\text{E}[X]	=	\e{\mu + \sigma^{2}/2}	=	g(\mu, \sigma)	=	g(\bm\theta)	\\
\end{equation*}
On peut trouver (\textit{pas démontré ici}) que les EMV sont:
\begin{align*}
	\hat{\mu}
	&=	\frac{1}{n} \sum_{i = 1}^{n} \ln x_{i}	&
	\hat{\sigma}
	&=	\frac{1}{n} \sum_{i = 1}^{n} (\ln x_{i} - \hat{\mu})^{2}	\\
\end{align*}
Donc, l'EMV de $g(\mu, \sigma)$ est:
\begin{equation*}
	g(\hat{\mu}, \hat{\sigma})	=	\e{\hat{\mu} + \hat{\sigma}^{2}/2}	=	g(\hat{\bm\theta})	\\
\end{equation*}
De plus, on peut trouver \textit{(encore, pas montré ici)} que la matrice de covariance est:
\begin{align*}
	\frac{\bm\Sigma}{n}
	=	\frac{1}{\bm{I}(\mu, \sigma)}	
	&=	\begin{bmatrix}
			\frac{\sigma^{2}}{n}	&	0						\\
			0					&	\frac{2\sigma^{4}}{n}	\\
		\end{bmatrix}
\end{align*}
où $\bm{I}$ est l'information de Fisher.

De plus:
\begin{align*}
	\bm{A}
	&=
	\begin{bmatrix}
		\deriv{\mu}g(\mu, \sigma)	\\
		\deriv{\sigma}g(\mu, \sigma)	\\
	\end{bmatrix}
	\Leftrightarrow
	\begin{bmatrix}
		\deriv{\theta_{1}}g(\bm\theta)	\\
		\deriv{\theta_{2}}g(\bm\theta)	\\
	\end{bmatrix}
	=
	\begin{bmatrix}
		\e{{\mu} + {\sigma}^{2}/2}	\\
		\sigma\e{{\mu} + {\sigma}^{2}/2}	\\
	\end{bmatrix}
\end{align*}
\setlength{\mathindent}{-1.5cm}

Finalement, on obtient:
\begin{align*}
	\text{E}[g(\hat{\mu}, \hat{\sigma})]	
	&=	\text{E}[g(\hat{\bm\theta})]
	\underset{n \rightarrow \infty}{=}	\e{\mu + {\sigma}^{2}/2}	
\end{align*}
\begin{align*}
	\text{Var}[g(\hat{\mu}, \hat{\sigma})]	
	&=	\text{Var}[g(\hat{\bm\theta})]	\\
	&\underset{n \rightarrow \infty}{=}	\hat{\bm{A}}^{\top} \frac{\hat{\bm{\Sigma}}}{n} \hat{\bm{A}}	\\
	&=	\Bigg[
	\begin{bmatrix}
		\e{\hat{\mu} + \hat{\sigma}^{2}/2}	\\
		\sigma\e{\hat{\mu} + \hat{\sigma}^{2}/2}	\\
	\end{bmatrix}^{\top} 
	\begin{bmatrix}
		\frac{\hat\sigma^{2}}{n}	&	0						\\
		0					&	\frac{2\hat\sigma^{4}}{n}	\\
	\end{bmatrix}
	\begin{bmatrix}
		\e{\hat{\mu} + \hat{\sigma}^{2}/2}	\\
		\sigma\e{\hat{\mu} + \hat{\sigma}^{2}/2}	\\
	\end{bmatrix} 
		\Bigg] _{\bm{\theta}}	\\
	&=	\e{2\mu + \sigma^{2}} \left( \frac{\sigma^{2}}{n} + \frac{\sigma^{4}}{2n} \right)
\end{align*}
\end{examplebox}

\setlength{\mathindent}{1cm}



\subsection*{Critères de sélection}

Le livre introduit 2 concepts:
\begin{description}
	\item[Parsimony:] À moins d'évidence considérable au contraire, le modèle le plus simple est toujours préféré.
	\item	Si on essaye assez de modèles, éventuellement un va sembler être bien ajusté même s'il ne l'est pas. 
	Il est donc essentiel de restreindre le nombre de modèles possibles.
\end{description}

De plus, le livre affirme qu'il y a deux méthodes de sélection de modèle; par jugement et par valeur de test.

Pour choisir entre plusieurs modèles selon une valeur, on peut, entre autres, se baser sur les critères suivants : 
\begin{enumerate}
\item la plus \textbf{faible valeur} pour le test \textbf{Kolmogorov-Smirnov} ; 
\item la plus \textbf{faible valeur} pour le test \textbf{Anderson-Darling} ;
\item la plus \textbf{faible valeur} pour le test \textbf{Goodness-of-fit} ;
\item la plus \textbf{haute valeur} pour la \textbf{\emph{p-value} du test Goodness-of-fit} ; 
\item la plus \textbf{haute valeur} pour la \textbf{fonction de vraisemblance à son maximum}.
\end{enumerate}

Le problème avec tous ces test (sauf la p-value du khi-carré) est qu'ils ne respectent pas le principe de \textit{parsimony}. 
Le modèle le plus complexe sera toujours préférable puisqu'il aura un meilleur ajustement pour les données.
La distinction avec la p-value du test du khi-carré est que le nombre de paramètres est pris en compte dans l'obtention du seuil.

Ceci est d'ailleurs d'où provient les tests d'AIC et de BIC. L'AIC pénalise les différents modèles selon le nombre de paramètres, le BIC les pénalisent proportionnellement au nombre d'observation.

\subsubsection*{Critère d'information d'Akaike (AIC) et critère Bayésien de Schwarz (BIC)}
On obtient alors que pour $n$ observation et un modèle avec $p$ paramètres:
\begin{itemize}
\item[AIC:] Ce critère est le plus utilisé dans la pratique et permet d'évaluer la qualité de l'ajustement d'un modèle. 
	\[ 
		AIC = - \ell + 2 p
	\]
L'AIC prend en compte à la fois la qualité des prédictions du modèle et sa complexité.
\item[BIC:] BIC est similaire à l'AIC, mais la pénalité des paramètres dépend de la taille de l'échantillon.
	\[ 
		BIC = \ell - \frac{p}{2} \ln n
	\]
\item On cherche donc à minimiser ces 2 critères.
\end{itemize}

\setcounter{section}{12}
\columnbreak
\section{Estimation bayésienne}

Avec l'estimation fréquentielle, on pose une distribution pour les données \textbf{fixée} \textit{\textbf{mais}} \textbf{inconnue}. De plus, nos décisions sont axées plus avec les possibilités liés à d'autres échantillons pouvant être obtenus qu'avec notre échantillon de données.

L'approche Bayésienne quant à elle pose que seul les données réellement observées sont pertinentes et que c'est la distribution de la population qui est variable.
L'approche est décrite par les définitions des distributions a priori et à postériori avec le théorème de Bayes pour trouver la solution.

\begin{definition}[Distribution \emph{a priori}]
Dénoté $\pi(\theta)$, représente nos opinions des chances que différentes valeurs de $\theta$ sont la vraie valeur du paramètre. 
Par conséquent, elle est définie sur l'espace des valeurs possible pour le paramètre $\theta$.
\end{definition}

La difficulté repose justement à déterminer une distribution a priori convaincante; pour traiter la possibilité d'avoir aucune ce qu'est la distribution a priori, on peut élargir la définition:
\begin{definition}[Distribution \emph{a priori} impropre]
Une distribution pour laquelle les probabilités (ou fonction de densité) sont non-négatives et dont leur somme (ou intégral) est infini.
\end{definition}

\begin{definitionNOHFILL}[Distribution du modèle]
Dénoté $f_{\bm{X} | \Theta}(\bm{x} | \theta)$, elle est la distribution de probabilité des données tel que collecté étant donné une valeur précise de $\theta$ 
\end{definitionNOHFILL}

\begin{rappel}{Rappel distribution conjointe et marginale}
Fonction conjointe:
\begin{equation*}
	f_{\bm{X}, \Theta}(\bm{x}, \theta)
	=	f_{\bm{X}|\Theta}(\bm{x} | \theta) \pi(\theta)
\end{equation*}
Fonction marginale de $\bm{x}$:
\begin{equation*}
	f_{\bm{X}}(\bm{x})
	=	\int f_{\bm{X}|\Theta}(\bm{x} | \theta) \pi(\theta) d\theta
\end{equation*}
\end{rappel}

\begin{definitionNOHFILL}[Distribution \emph{a posteriori}]
Dénoté $\pi_{\Theta | \bm{X}}(\theta | \bm{x})$, elle représente la distribution de probabilité des paramètres conditionnelle aux données observées. 
La distribution \emph{a posteriori} nous permet donc de savoir avec quelle probabilité (non-nulle) les paramètre $\bm\theta$ peuvent prendre certaine valeurs spécifiques sachant qu'on a observé certains $x$: 
\begin{equation}
\label{eq:dist_posteriori}
	\pi_{\Theta | \bm{X}}(\theta | \bm{x})
	= 	\frac{f_{\Theta | \bm{X}}(\theta | \bm{x})}{f_{X}(x)} 
	= 	\frac{f_{\bm{X}|\Theta}(\bm{x} | \theta) \pi(\theta)}{\int f_{\bm{X}|\Theta}(\bm{x} | \theta) \pi(\theta) d\theta} 
\end{equation}

L'idée est de remplacer les différentes distributions dans l'\autoref{eq:dist_posteriori}, et en déduire une distribution avec une paramétrisation différente\footnote{Souvent, la distribution \emph{a posteriori} aura la même distribution que celle \emph{a priori}, mais avec des paramètres différents.}.
\end{definitionNOHFILL}

De plus, on défini la distribution pour les nouvelles observations:
\begin{definitionNOHFILL}[Distribution prédictive du modèle]
Dénoté $f_{Y | \bm{X}}(y | \bm{x})$, elle est la distribution de probabilité d'une nouvelle observation $y$ étant étant donné les données $\bm{x}$.

La fonction de densité d'une nouvelle observation étant donné la valeur du paramètre.
\begin{equation*}
	f_{Y | \bm{X}}(y | \bm{x})
	=	\int f_{Y|\Theta}(y | \theta) \pi_{\Theta | \bm{X}}(\theta | \bm{x}) d\theta
\end{equation*}

\end{definitionNOHFILL}


\paragraph{L'estimateur Bayésien} L'estimateur Bayésien est défini comme l'espérance du paramètre $\theta$, sachant la distribution de $X$. 
En d'autres mots, on veut l'espérance de la distribution \emph{a posteriori} : 

\begin{algo}{Estimateur Bayésien}
\begin{equation}
\label{eq:estimateur_bayes}
	\hat{\theta}_{BAYES} 
	=	\esp{\Theta | X}
\end{equation}
\end{algo}

\setcounter{section}{-1}
\columnbreak
\section{Rappel de probabilité}
\subsection*{Certaines lois à savoir}
\begin{tabular}{|a| * {4}{C|}}
	\hline
	\rowcolor{red!30!white}
	\text{Loi} 				&	\prob{X = x} \text{ ou } f_X(x) 		&	\esp{X}	&	Var(X) 	& 	M_X(t) 							\\\hline
	Bin(n,p)					& 	\binom{n}{x} p^x (1-p)^{n-x} 		&	np 		&	np(1-p) 	& 	\left( (1-p) + p^t \right)^n 	\\\hline
	Pois(\lambda) 			&	\frac{e^{-\lambda} \lambda^x}{x!} 	&	\lambda 	& 	\lambda 	& 	e^{\lambda(t-1)} 				\\\hline
	Gamma(\alpha, \lambda) 	& 	\frac{\lambda^{\alpha} x^{\alpha-1} e^{-\lambda x}}{\Gamma(\alpha)} 						& 	\frac{\alpha}{\lambda} 	&	\frac{\alpha}{\lambda^2}	& 	\left( \frac{\lambda}{\lambda - t} \right)^\alpha 	\\\hline
	Normale(\mu, \sigma^2) 	& 	\frac{1}{\sqrt{2 \pi} \sigma} e^{- \frac{1}{2} \left( \frac{x-\mu}{\sigma} \right)^2} 	& 	\mu 						&	\sigma^2 					& 	e^{\mu t + \frac{\sigma^2 t^2}{2}} 				\\\hline
\end{tabular}
 
\subsection*{Rappels d'algèbre linéaire}
\subsubsection*{Matrice transposée} la matrice transposée est définie par $\bm{A}^\top$, telle que
\begin{align*}
\bm{A}^{\top} & = 
\begin{bmatrix}
a	& -c \\
-b	& d \\
\end{bmatrix}
\end{align*}

\subsubsection*{Déterminant d'une matrice} On peut calculer le déterminant $\det(\bm{A})$ de la matrice $\bm{A}$ tel que
\begin{align*}
\det(\bm{A})	  = 
\begin{vmatrix}
a	& b \\
c	& d \\
\end{vmatrix}
= ad - bc
\end{align*}

\subsubsection*{Inverse d'une matrice} L'équivalent de l'opération $\frac{1}{\bm{A}}$ en algèbre linéaire est de calculer la matrice inverse de $\bm{A}^{-1}$, telle que		
\begin{align*}
\bm{A}^{-1}	& = \frac{1}{\det(\bm{A})}
\begin{bmatrix}
d	& -c \\
-b	& a \\
\end{bmatrix}
\end{align*}
où on multiple par la matrice adjointe de $\bm{A}$. Il faut normalement calculer les cofacteurs, mais le cas à 2 dimensions est un cas simplifié.

\pagebreak

\end{multicols*}


%% -----------------------------
%% Fin du document
%% -----------------------------
\end{document}
