%% Aide-mémoire
\documentclass[10pt, french, landscape]{article}
%% -----------------------------
%% Préambule
%% -----------------------------
\input{cheatsht-preamble-general.tex}
%% -----------------------------
%% Variable definition
%% -----------------------------
\def\cours{Processus Stochastiques}
\def\sigle{ACT-2009}
\def\SectionColor{blue!80!white}
\def\SubSectionColor{blue!30!black}
\def\SubSubSectionColor{blue!30!black}
%% -----------------------------
%% Début du document
%% -----------------------------
\begin{document}

\begin{center}
	\textsc{\Large Contributeurs}\\[0.5cm] 
\end{center}
\input{contributeurs/contrib-ACT2009}

\newpage

\small
\begin{multicols*}{2} % Nombre de colonnes (peut être changé plus tard.)
\section{Probabilités conditionnelles}
\begin{enumerate}[label=\faAngleRight]
\item Rappel théorème de Bayes : 
\begin{align*}
\prob{A | B} = \frac{\prob{A \cap B}}{\prob{B}} = \frac{\prob{B|A} \prob{A}}{\prob{B}}
\end{align*}

\item Distribution conditionnelle : 
\begin{align*}
\prob{X_1 = x_1 | X_2 = x_2} & = \frac{\prob{X_1 = x_1, X_2 = x_2}}{\prob{X_2 = x_2}} \\
\end{align*}

\item L'espérance d'une fonction conditionnelle : 
\begin{align*}
\esp{g(X_1) | X_2 = x_2} = \sum_{i=0}^{\infty} g(x) \prob{X_1 = x_1 | X_2 = x_2}
\end{align*}

\item La variance d'une fonction conditionnelle :
\begin{align*}
\mathrm{Var} (g(X_1) | X_2) = \esp{g(X_1)^2 |X_2} - \esp{g(X_1) | X_2}^2
\end{align*}

\item L'espérance conditionnelle : 
\begin{align*}
\esp{X_1} 	& = \esp{\esp{X_1 | X_2}} \\
			& = \sum_{x_2 = 0}^{\infty} \esp{X_1 | X_2} \prob{X_2 = x_2} \\
\esp{X_1}	& = \esp{\esp{X_1 | X_2}} \\
			& = \int_{-\infty}^{\infty} \esp{X_1 | X_2} f_{X_2}(x_2) d x_2 \\
\end{align*}

\item La variance conditionnelle : 
\begin{align*}
\mathrm{Var} (X_1) = \esp{\mathrm{Var} (X_1 | X_2)} + \mathrm{Var} \left( \esp{X_1 | X_2} \right)
\end{align*}
\end{enumerate}

Lorsqu'il y a 3 v.a., l'espérance devient
\begin{align*}
\esp{X_1 | X_2}	& = \esp{\esp{X_1 | X_2, X_3} | X_2} \\
	& = \sum_{x_3 = 0}^{\infty} \esp{X_1 | X_2, X_3} \prob{X_3 = x_3 | X_2 = x_2} \\
	& = \int_{-\infty}^{\infty} \esp{X_1 | X_2, X_3} f_{X_3| X_2}(x_3 | x_2) dx_3
\end{align*}
La variance conditionnelle devient
\begin{align*}
Var(X_1) = \esp{Var(X_1 | X_2, X_3)}  + \mathrm{Var} \left( \esp{X_1 | X_2, X_3} \right)
\end{align*}
De plus,
\begin{align*}
\covar{X, Y} = \esp{\covar{X, Y | Z}} + \covar{\esp{X | Z}, \esp{Y | Z}}
\end{align*}


Soit $N$, le nombre d'essais indépendants jusqu'à avoir un même résultat k fois consécutivement avec m possibilités équiprobables.
\begin{align*}
	\esp{N} &= \frac{1 - m^{k}}{1 - m} \\
\end{align*}

%\subsection*{Poisson composée}
%\begin{enumerate}[label=\faAngleRight]
%\item Soit $S = X_1 + ... + X_N$, où les $X_i$ sont \textit{iid}, $N \sim Pois(\lambda)$ est stochastiquement indépendant des $X_i$. Alors, on a
%\begin{align*}
%\esp{S h(S)} = \lambda \esp{X h(S+X)}
%\end{align*}
%
%\item On peut aussi trouver que
%\begin{align*}
%\esp{S^n} = \lambda \sum_{j=0}^{n-1} \binom{n-1}{j} \esp{S^j} \esp{X^{n-j}}
%\end{align*}
%\end{enumerate}

%\subsection*{Mesures de risque}
%\begin{enumerate}[label=\faAngleRight]
%\item Value-At-Risk ($VaR$) : représente le quantile au niveau $\kappa$ de $X$.
%\begin{align*}
%VaR_\kappa(X) = F_X^{-1}(\kappa) = \inf \{ x \geq 0 : F_X(x) \geq \kappa \}
%\end{align*}
%
%\item Tail Value-At-Risk (aussi appelée \textit{Conditional Tail Expectation})  : représente la perte moyenne de $X$, sachant qu'elle est au dessus de la valeur $VaR_\kappa(X)$.
%\begin{align*}
%TVaR_\kappa(X) & = \esp{X | X > VaR_\kappa(X)} \\
%	& = \int_{0}^{\infty} x f_{X | X > VaR_\kappa(X)}(x) dx \\
%	& = \int_{VaR_\kappa(X)}^{\infty} \frac{x f_X(x)}{\overline{F}_X(VaR_\kappa(X))} dx \\
%	& = \frac{1}{1 - \kappa} \int_{VaR_\kappa(X)}^{\infty} x f_X(x) dx \\
%\end{align*}
%\end{enumerate}

\vfill\null

\section{Processus Stochastiques}

\subsection*{Définition}
\begin{description}
	\item[Domaine]: Valeurs possible du processus à un temps quelconque t. \\
	Exemple: Température est dans un certain intervalle, $\Omega \in [-50, 50]$.
	\item[Filtration]: Information connue au temps t.\\
	Exemple: Température dépend de la température passée, peu probable qu'il neige s'il faisait 35 hier.
	\item[Probabilités]: Probabilité des événements possibles.\\
	Exemple: Température possède certaines probabilités, 70\% de plus demain, 40\% dans 2 jours, etc.
\end{description}

Dénoté par $\{X(t), t \in T\}$.
Si l'ensemble est:
\begin{description}
	\item[fini ou dénombrable]: Processus est dit d'être \textbf{en temps discret}.
	\item[infini ou non-dénombrable]: Processus est dit d'être \textbf{en temps continu}.
\end{description}

Si l'ensemble des valeurs possibles de $X(t)$ est:
\begin{description}
	\item[fini ou \textit{infini} dénombrable]: Processus est dit d'avoir un espace d'état \textbf{discret}
	\item[infini ou non-dénombrable]: Processus est dit d'avoir un espace d'état \textbf{continu}
\end{description}

\subsection*{Fonctions}

Fonction de répartition d'ordre $k$ du processus $\{X(t), t \in T\}$.
	\begin{align*}
		F(x_{1}, \dots, x_{k} \ ; \ t_{1}, \dots, t_{k}) &= \text{Pr}(X(t_{1}) \le x_{1}, \dots, X(t_{k}) \le x_{k})
	\end{align*}
	
Fonction de densité d'ordre $k$ du processus $\{X(t), t \in T\}$.
	\begin{align*}
		f(x_{1}, \dots, x_{k} \ ; \ t_{1}, \dots, t_{k}) &= \frac{\partial^{k}}{\partial_{x_{1}} \dots \partial_{x_{k}}} F(x_{1}, \dots, x_{k} \ ; \ t_{1}, \dots, t_{k})
	\end{align*}

Fonction de probabilité de masse d'ordre $k$ du processus $\{X(t), t \in T\}$.
	\begin{align*}
		\text{p}(x_{1}, \dots, x_{k} \ ; \ t_{1}, \dots, t_{k}) &= \text{Pr}(X(t_{1}) = x_{1}, \dots, X(t_{k}) = x_{k})
	\end{align*}
	
\subsection*{Moments}

Moyenne à l'instant $t$, alias moment d'ordre $t$.
\begin{align*}
	m_{x}(t) &= \esp{X(t)}
\end{align*}

Auto-covariance en $\{t_{1}, t_{2} \}$.
\begin{align*}
	\text{Cov}(X(t_{1}), X(t_{2})) &= \esp{X(t_{1}),X(t_{2})} - m_{x}(t_{1}) m_{x}(t_{2})
\end{align*}

Auto-corrélation en $\{t, t - 1 \}$.
\begin{align*}
	\rho_{\text{auto}}(X(t)) &= \frac{\text{Cov}(X(t), X(t - 1))}{\sqrt{\text{V}(X(t))\text{V}(X(t - 1))}} \\
	&\overset{\text{stationnaire}}=  \frac{\text{Cov}(X(t), X(t - 1))}{\text{V}(X(t))}
\end{align*}

\subsection*{Propriétés}

Les accroissement sont:
\begin{description}
	\item[Indépendants] si les v.a. $X(t_{4}) - X(t_{3})$ et $X(t_{2}) - X(t_{1})$ sont \textbf{indépendants} $\forall	t_{1} \le t_{2} \le t_{3} \le t_{4}$.
	\item[Stationnaires] si les v.a. $X(t_{2} + s) - X(t_{1} + s)$ et $X(t_{2}) - X(t_{1})$ possèdent la même fonction de répartition $\forall	s$.
	\begin{align*}
		F(x_{1}, \dots, x_{n} \ ; \ t_{1}, \dots, t_{n}) &= F(x_{1}, \dots, x_{n} \ ; \ t_{1} + s, \dots, t_{n} + s)
	\end{align*}
\end{description}



\section{Chaînes de Markov}
\subsection*{Définition}
Une chaîne de Markov est homogène si
\begin{align*}
\prob{X_{n+1} = j | X_{n}=i, ..., X_0 = i_0} & = \prob{X_{n+1} = j | X_n = i}  \\
 & = p_{ij} \\
\end{align*}
On définit la matrice des probabilités de transition
\begin{align*}
P &= [p_{ij}]_{i \times j} \\
&= \left[
\begin{matrix}
	P_{00} & P_{01} & P_{02} & \dots \\
	P_{10} & P_{11} & P_{12} & \dots \\
	P_{20} & P_{21} & P_{22} & \dots \\
	\vdots & \vdots & \vdots & \ddots \\
\end{matrix}
\right]
\end{align*}

\subsection*{Équation de Chapman-Kolmogorov}
\begin{align*}
p_{ij}^{(n)} 	& = \prob{X_{k+n} = j | X_k = i} \\
p_{ij}^{(n+m)} 	& = \sum_{k=0}^{\infty} p_{ik}^{(n)} p_{kj}^{(m)} \\
\end{align*}
Note : soit $P$ la matrice des probabilités de transition. On peut trouver $P^{(n+m)} = P^{(n)} \cdot P^{(m)}$, avec $P^{(n)} = P^n = P\cdot P \cdot P \cdot ... \cdot P$.

\begin{align*}
\prob{X_n = j} & = \sum_{i=0}^{\infty} p_{ij}^{(n)} p_{x_0}(i) \\
	& = \sum_{i=0}^{\infty} \prob{X_n = j | X_0 = i} \prob{X_0 = i} \\
\end{align*}

\subsection*{États accessibles et communicants}
\begin{enumerate}[label=\faAngleRight]
\item $j$ est accessible de $i$ si $p_{ij}^{(n)} >0$, pour $n \in \naturels$.

\item si $i$ et $j$ sont accessibles réciproquement ($i \leftrightarrow i$), alors ils sont \textbf{communicants}. Ils forment donc une classe (ainsi que les autres états communicants).

\item Une chaîne de Markov est dite \underline{irréductible} si elle est composée d'une seule classe.
\end{enumerate}

\subsubsection*{Propriété d'une classe}
\begin{enumerate}[label=\faCheck]
\item Réflexibilité : $p_{ii}^{(0)} = 1$.
\item Symétrie : $i \leftrightarrow j$ est équivalent à $j \leftrightarrow i$.
\item Transitivité : si $i$ communique avec $j$ (i.e. $p_{ij}^{(n)} >0$) et que $j$ communique avec $k$ (i.e. $p_{jk}^{(m)}>0$), alors
\begin{align*}
p_{ik}^{(n+m)} = \sum_{r=0}^{\infty} p_{ir}^{(n)} p_{rk}^{(m)} \geq p_{ij}^{(n)} p_{jk}^{(m)} > 0
\end{align*}
\end{enumerate}

\subsection*{États récurrents, transcients et absorbants}
\begin{enumerate}[label=\faAngleRight]
\item $f_{ii}$ : probabilité de revenir éventuellement à l'état $i$ en ayant comme point de départ $i$.
\item 
\begin{multicols*}{2}
\textbf{État récurrent} 
\begin{align*}
&	f_{ii} = 1 \\
&	\sum_{n = 1}^{\infty} P_{ii}^{(n)} = \infty 
\end{align*}
\newpage
\textbf{État transcient}
\begin{align*}
&	f_{ii} < 1 \\
&	\sum_{n = 1}^{\infty} P_{ii}^{(n)} < \infty 
\end{align*}
\end{multicols*}
\item Si l'état $i$ est récurrent et que $i \leftrightarrow j$, alors $j$ est récurrent aussi.
\item $f_{ii}^{(n)}$ : probabilité de revenir à l'état $i$ pour la première fois après $n$ étapes.
\item Une chaîne de Markov irréductible avec espace d'état fini \textbf{n'a que des états récurrents}.
\item \textbf{État absorbant} : $j$ est un état absorbant si $p_{jj} = 1$. De plus, Si $j$ est un état absorbant, alors
\begin{align*}
f_{ij} = \sum_{k=0}^{m} p_{ik} f_{kj}
\end{align*}
\end{enumerate}

\subsection*{Probabilité limites}
\begin{enumerate}[label=\faAngleRight]
\item \textbf{État périodique} : si l'état a une période $d$, alors il sera possible de revenir à cet état après $n$ étapes, qui est un multiple de $d$. i.e
\begin{align*}
d(i) = P.G.C.D\{n \in \naturels ~ | ~ p_{ii}^{(n)} > 0 \}
\end{align*}
\item si $d(i)=1$, alors l'état $i$ est \textbf{apériodique}.
\item La périodicité est une propriété de classe : si $i \leftrightarrow j$, alors $d(i) = d(j)$.
\item Le temps de retour moyen pour l'état $i$ est défini par
\begin{align*}
\mu_{ii} = \sum_{n=1}^{\infty} n f_{ii}^{(n)}
\end{align*}
avec $\pi_i = \frac{1}{\mu_{ii}}$

\item \textbf{État récurrent positif} : si, à partir de l'état $i$, le temps de retour moyen $\mu_{ii}$ à l'état $i$ est fini, alors l'état $i$ est récurrent positif.

\item \textbf{État ergodique} : un état qui est à la fois apériodique et récurrent positif.

\item Si une Chaîne de Markov est irréductible et que tout ses états sont ergodiques, alors
\begin{enumerate}[label=(\arabic*)]
	\item $	\lim_{n \to \infty} p_{ij}^{(n)} = \pi_j < \infty$
	\item $\pi_j = \sum_{i=0}^{\infty} \pi_i p_{ij}$
	\item $\sum_{j=0}^{\infty} \pi_j = 1$
\end{enumerate}

\item On peut alors résoudre un système d'équations pour trouver nos $\pi_i$.
\end{enumerate}

\subsection*{Système Bonus Malus}

\begin{enumerate}
	\item[$s_{i}(k)$ : ] Le prochain état d'un assuré dans l'état $i$ ayant eu $k$ accidents.
	\item[$a_{k}$ : ] Probabilité qu'un assuré ait $k$ accidents.
\end{enumerate}

\section{Processus de Poisson}
Soit $N(t)$ le nombre d'évènements qui se sont produits dans l'intervalle $t$.

\subsection*{Définitions}

\begin{definition}[Définition 1]
Un processus de dénombrement $\{N(t) ; t \geq 0 \}$ est dit un processus de Poisson avec $\lambda >0$ ssi
\begin{enumerate}[label=(\arabic*)]
\item $N(0)=0$
\item Le processus a des accroissements indépendants, i.e pour $0 \leq t_1 \leq t_2 < t_3$, les accroissements $(N(t_3) - N(t_2))$ et $(N(t_2)-N(t_1))$ sont stochastiquement indépendants.
\item $\forall t \ $, $(N(s+t) - N(s)) \sim Pois(\lambda t)$. Alors,
\begin{align*}
\prob{N(s+t) - N(s) = n} = \frac{(\lambda t)^n e^{-\lambda t}}{n!}
\end{align*}
\end{enumerate}
\end{definition}

\begin{definition}[Définition 2]
Un processus de dénombrement $\{N(t) ; t \geq 0 \}$ est dit un processus de Poisson avec $\lambda>0$ ssi
\begin{enumerate}[label=(\arabic*)]
\item $N(0)=0$
\item a des accroissements indépendants et stationnaires
\item $\prob{N(h) = 1} = \lambda h + o(h)$
\item $\prob{N(h) \geq 2} = o(h)$
\end{enumerate}
Avec $o(h)$ une fonction où $f(h) = o(h)$ si $\lim_{n \to \infty} \frac{f(h)}{h} = 0$.
\end{definition}
On peut prouver que ces 2 définitions sont équivalentes.

\subsubsection*{Rappels sur la loi de Poisson}
La fonction génératrice des moments de $X \sim Pois(\lambda)$ est
\[ M_X(t) = \esp{e^{tX}}  = e^{-\lambda(e^{t} -1)} \]


\subsection*{Temps séparant 2 évènements successifs}\begin{enumerate}[label=\faAngleRight]
\item Soit $T_i$ le temps entre le $(i-1)$\up{e} et le $i$\up{e} évènement.

\item Alors, $T_n \sim Exp (\lambda)$.

\item Soit $S_n$ le moment où se produit le $i$\up{e} évènement. On a
\begin{align*}
S_n = \sum_{i=1}^{n} T_i
\end{align*}
\item On peut facilement prouver que $S_n \sim \Gamma(n, \lambda)$.

\item Si $N(t) \geq n$, alors nécessairement $S_n \leq t$.
\end{enumerate}

\subsection*{Évènements de 2 processus différents}

Probabilité que $n$ évènements d'un processus se produisent avant $m$ évènements d'un autre.

Il y a plusieurs interprétations possible.

Rendu au $n + m - 1$ème évènement au total, il y en a au moins $n$ qui proviennent du 1er type.

\begin{align*}
	\Pr(S_{n}^{1} < S_{m}^{2}) 
	&=	\sum_{k = n}^{n + m - 1} \binom{n + m - 1}{k} \left( \frac{\lambda_{1}}{\lambda_{1} + \lambda_{2}}\right)^{k} \left( \frac{\lambda_{2}}{\lambda_{1} + \lambda_{2}}\right)^{n + m - 1 + k}
\end{align*}

Rendu au $n$ème évènement du 1er type, j'en ai au plus $m - 1$ du 2ème type.

\begin{align*}
	\Pr(S_{n}^{1} < S_{m}^{2}) 
	&=	\sum_{k = 0}^{m - 1} \binom{n + k - 1}{k} \left( \frac{\lambda_{1}}{\lambda_{1} + \lambda_{2}}\right)^{n} \left( \frac{\lambda_{2}}{\lambda_{1} + \lambda_{2}}\right)^{k}
\end{align*}

\subsection*{Processus de Poisson avec évènements de type I et II}
\begin{enumerate}[label=\faAngleRight]
\item Soit un Processus de Poisson $\{N(t) ; t \geq 0 \}$ où il peut y avoir un évènement de type I avec probabilité $p$ ou un de type II avec probabilité $q$.
\item Nécessairement, on a
\begin{align*}
N(t) = N_1(t) + N_2(t)
\end{align*}
Avec $N_1(t)$ et $N_2(t)$ qui sont stochastiquement indépendants.

\item $N_i(t) \sim Pois(\lambda p_i t)$, où $p_i$ est la probabilité que l'évènement de type $i$ se produise.
\end{enumerate}


\subsection*{Distribution conditionnelle des temps d'occurence}
\begin{itemize}
\item Pour un processus de Poisson $\{ N(t) ; t \geq 0 \}$, la distribution conditionnelle des temps d'occurence $S_1, ... S_n$ sachant que $N(t) = n$ est définie par
\begin{align*}
f_{S_1, ..., S_n | N(t)}(s_1, ..., s_n | n) = \frac{n!}{t^n}
\end{align*}
pour $0 < s_1 < ... < s_n$.

\item La distribution de $S_1, ..., S_n | N(t) = n$ a la même distribution que les statistiques d'ordre : 
\begin{align*}
U_{(1)}, ..., U_{(n)} \sim U(0,t)
\end{align*}
\end{itemize}

\subsection*{Processus de Poisson non-homogène}

On a que les accroissements ne sont plus stationnaires, les évènements sont plus susceptibles d'arriver à certains moments que d'autres.

\begin{definition}[Définition]
Un processus de dénombrement $\{ N(t) ; t \geq 0 \}$ est dit être un processus de Poisson non-homogène avec fonction d'intensité $\lambda(t)$ si
\begin{enumerate}[label=(\arabic*)]
\item $N(0) = 0$ ;
\item $\{ N(t) ; t \geq 0 \}$ a des accroissements indépendants ;
\item $\prob{N(t+h) - N(t) = 1} = \lambda(t) h + o(h)$ ;
\item $\prob{N(t+h) - N(t) \geq 2} = o(h)$ où $o(h)$ est une fonction négligeable.
\end{enumerate}
\end{definition}

\subsubsection*{Proposition 1}
\[\prob{N(t+s) - N(t) = n}  = \frac{\left(m(t+s) - m(s) \right)^n}{n!} e^{-(m(t+s) - m(s))} \]
où $m(t) = \int_{0}^{t} \lambda(x) dx$. On a alors que
\[N(t+s) - N(s) \sim Pois(m(t+s) - m(s))\]


\subsubsection*{Proposition 2}
Si $S_n$ désigne le temps d'occurence du $n$\up{e} évènement, alors
\[f_{S_n}(t) = \lambda(t) \frac{m(t)^{n-1}}{(n-1)!} e^{-m(t)} \]

\subsubsection*{Proposition 3}
Si $T_n = S_{n} - S_{n-1}$, alors on a, pour $n \geq 2$,
\[f_{T_n}(t) = \frac{1}{(n-2)!} \int_{0}^{\infty} \lambda(s) \lambda(t+s) m(s)^{n-2} e^{-m(t+s)} ds \]

\subsection*{Processus de Poisson composé}
\begin{definition}[Définition]
Un processus stochastique $\{ N(t) ; t \geq 0  \}$ est dit être un processus de Poisson composé s'il peut être représenté comme suit : 
\[X(t) = \sum_{i=1}^{N(t)} Y_i\]
où $\{ N(t) ; t \geq 0  \}$ est un Processus de Poisson avec paramètre $\lambda > 0$ et $\{ Y_i ; i \in \naturels \}$ est une suite de v.a. \emph{iid} indépendantes de $N(t)$.

De plus:
\begin{align*}
	\text{E}[X(t)]	&=	\lambda t \text{E}[Y_1]	&
	\text{Var}[X(t)]	&=	\lambda t \text{E}[Y_1^{2}]
\end{align*}
\end{definition}

\subsubsection*{Proposition 1}
Soit $\{ X(t) ; t \geq 0 \}$ un processus de Poisson composé avec paramètre $\lambda > 0$ et supposons que $\prob{Y_i = \alpha_j} = p_j$, $\sum p_j = 1$. Alors,
\[X(t) = \sum_j \alpha_j N_j(t) \]
où $N_j(t)$ est le nombre de fois que se produit l'évènement $\alpha_j$ dans l'intervalle de temps $[0,t]$, et $\{N(t) ; t \geq 0  \}$ forme une suite de v.a. indépentantes telles que $N_j(t) \sim Pois(\lambda p_j t)$. \\
Lorsque $t \to \infty$, alors $X(t)$ est asymptotiquement normal, i.e.
\[X(t) \sim \mathcal{N}\left( \lambda t \esp{Y}, \lambda t \esp{Y^2} \right)\]

\subsubsection*{Proposition 2}
Si $\{ X(t) ; t \geq 0 \}$ et $\{ Y(t) ; t \geq 0 \}$ sont 2 processus de Poisson composés indépendants avec paramètres et fonctions de répartition $\lambda_1, F_{X_1}$ et $\lambda_2, F_{Y_1}$ respectivement, alors $\{ X(t) + Y(t) ; t \geq 0 \}$ est aussi un processus de Poisson composé avec paramètre $\lambda_1  \lambda_2$ et fonction de répartition $F_{X_1 + Y_1}$ telle que
\[F_{X_1 + Y_1} = \frac{\lambda_1 F_{X_1} + \lambda_2 F_{Y_1}}{\lambda_1 + \lambda_2}  \]

\subsection*{Processus de Poisson conditionnel}
\begin{definition}[Définition]
Un processus de dénombrement avec un taux aléatoire $\Lambda > 0$ est un processus de Poisson conditionnel si $\{ N(t) | \Lambda = \lambda ; t \geq 0 \}$ est un processus de Poisson avec taux $\lambda > 0$.
\end{definition}

\subsubsection*{Rappel sur la loi Gamma}
La fonction de répartition de la loi Gamma, lorsque $\alpha \in \entiers$, est définie par
\[F_X(x) = 1 - \sum_{k=1}^{\alpha-1} \frac{(\lambda x)^k e^{-\lambda x}}{k!}\]
De plus, on a $\Gamma(\alpha) = (\alpha-1)!$ et $\Gamma(\alpha) = (\alpha - 1) \Gamma(\alpha - 1)$. Aussi, la transformée de Laplace pour $X \sim \Gamma(\alpha, \theta)$ est
\[\laplace_X(s) = \esp{e^{-s X}}  = \left( \frac{\lambda}{\lambda + s} \right)^{\alpha} \]

\subsubsection*{Remarques importantes}
\begin{enumerate}[label=(\arabic*)]
\item Un processus de Poisson conditionnel a des accroissements stationnaires (i.e. l'accroissement ne dépend pas d'où on est, mais plutôt de l'intervalle de temps) ; 
\item Mais le processus de Poisson conditionnel n'a pas nécessairement des accroissements indépendants ;
\item Identité Poisson-Gamma : si on a $\Lambda \sim \Gamma(m, \theta)$, alors
\[N(t) \sim NB\left(r = m, p = \frac{\theta}{\theta + t} \right) \]

\item L'espérance et la variance d'un processus de Poisson conditionnel sont définies par
\begin{align*}
\esp{N(t)} & = t \esp{\Lambda} \\
\variance{N(t)} & =  t \esp{\Lambda} + t^2 \variance{\Lambda}
\end{align*}

\item En utilisant le théorème de Bayes, on peut trouver la fonction de répartition $F_{\Lambda | N(t)}(x | n)$ et fonction de densité $f_{\Lambda | N(t)}(x | n)$ telles que
\begin{align*}
F_{\Lambda | N(t)}(x | n)	& = \frac{\prob{\Lambda \leq x | N(t) = n}}{\prob{N(t) = n}} \\
& = \frac{\prob{N(t) = n | \Lambda} f_\Lambda(\lambda) d \lambda}{\int_{0}^{\infty} \prob{N(t) = n | \Lambda = \lambda} f_\Lambda(\lambda) d\lambda} \\
\end{align*}

\item On a, $\forall t > 0$,
\begin{align*}
\prob{N(t) > n} = \int_{0}^{\infty} \overline{F}_{\Lambda}\left( \frac{x}{n} \right) \frac{x^n}{n!} e^{-x} dx
\end{align*}
\end{enumerate}

\section{Processus de renouvellement}

Un processus de renouvellement est un processus de comptage t.q. le temps entre le $(n - 1)$ et $n^{\text{ème}}$ événement a une distribution $F$ indépendamment du moment où le $(n-1)^{\text{ème}}$ évènement arrive. Donc, puisque c'est la même distribution $F$ pour tous les évènements, lorsqu'un évènement se produit on dit qu'un \textbf{\textit{renouvellement}} s'est produit.

On peut donc voir qu'avec les processus de Poisson on se concentre plus sur le dénombrement alors qu'avec les processus de renouvellement ce sont le temps entre évènements qui est d'intérêt.

\subsection*{Définitions générales}
\begin{itemize}
\item $T_n$ : intervalle de temps entre le $(n-1)$\up{e} et le $n$\up{e} renouvellement ;
\item $S_n = \sum_{i=1}^{n} T_i$ : le temps d'occurence du $n$\up{e} renouvellement. On va souvent noter $S_{N(t)}$, avec $N(t)$ comme temps d'arrêt du processus\footnote{$N(t)$ est le temps d'arrêt dans le sens où on cesse le processus de dénombrement lorsqu'on atteint $N(t)$.} ;
\item $F(0) = \Pr(T = 0) < 1$ pour éviter que le processus reste \textit{pris} à 0;
\item $\mu = \esp{T_n} > 0$ : temps moyen d'attente entre 2 renouvellements où $n \geq 1$ ;
\end{itemize}

\subsection*{Distribution de $N(t)$}
On définit $N(t)$ comme $N(t) = \max \{ n : S_n \leq t \}$. Alors,
\begin{align*}
\prob{N(t) = n} = F_T^{\ast n}(t) - F_T^{\ast(n+1)}(t)
\end{align*}
Dans le cas où $T \sim Erlang(m, \lambda)$, alors
\[\prob{N(t) = n}  = \sum_{k=mn}^{m(n+1) - 1} \frac{(\lambda x)^k e^{-\lambda x}}{k!} \]

\subsection*{Fonction de renouvellement}
La fonction de renouvellement est le nombre moyen d'occurences dans l'intervalle $[0,t]$  :
\[m(t) = \esp{N(t)} = \sum_{n=1}^{\infty} F_T^{\ast(n)}(t)  = \sum_{n=1}^{\infty} S_{N(t)}(t)  \]

\subsubsection*{Solution de l'équation de renouvellement}
$m(t)$ satisfait \emph{l'équation de renouvellement}, soit
\[m(t) = F_T(t) + \int_{0}^{t} m(t-x) f_T(x) dx  \]

\subsubsection*{Relation biunivoque entre $m(t)$ et $F_T$}
Avec la transformée de Laplace de $m(t)$, $\hat{m}(s)$, on a
\begin{align*}
\hat{m}(s) &  = \frac{\hat{f}_T(s)}{s} + \hat{m}(s) \hat{f}_T(s) \\
& = \frac{\hat{f}(s)}{s\left(1 - \hat{f}(s)    \right)}
\end{align*}


\subsection*{Théorèmes limites}
\begin{enumerate}[label=(\arabic*)]
\item On a que $N(\infty) = \infty$ avec probabilité 1. De plus,
\begin{align*}
\frac{N(t)}{t} \underset{t \to \infty}{\longrightarrow} \frac{1}{\esp{T}}
\end{align*}
avec une probabilité \emph{presque certaine}.

\item \emph{Théorème élémentaire du renouvellement} : avec $t \to \infty$, on a
\[\frac{m(t)}{t} \underset{t \to \infty}{\longrightarrow} \frac{1}{\esp{T}} \]

\item Lorsque $t \to \infty$, $N(t)$ est aymptotiquement normale, telle que
%\begin{align*} % version sous forme de \Phi
%\frac{N(t) - \frac{t}{\esp{T}}}{\sqrt{\frac{t \variance{T}}{\esp{T}^3}}} \sim \mathcal{N} (0,1)
%\end{align*}

\begin{flalign*} % version 2
N(t) \sim \mathcal{N} \left( \frac{t}{\esp{T}},  \frac{t \variance{T}}{\esp{T}^3}   \right)
\end{flalign*}
\end{enumerate}

\subsection*{Équation de renouvellement}
De façon générale, si on a une équation intégrale d'une fonction $g(t)$ telle que
\[g(t) = h(t) + \int_{0}^{t} g(t-x) dF_T(x) \]
Alors, la seule solution est
\[g(t) = h(t) + \int_{0}^{t} h(t-x) d m(x) \]

\subsection*{Distribution de $S_{N(t)}$}
On peut définir la fonction de répartition et l'espérance de $S_{N(t)}$ comme
\[F_{S_{N(t)}}(x) = \overline{F}_T(t) + \int_{0}^{x} \overline{F}_T(t-y) dm(y)  \]
et
\[\esp{S_{N(t)}}  = t F_T(t) - \int_{0}^{t} (t-y)\overline{F}_T(t-y) d m(y) \]
De plus, selon l'équation de Wald\footnote{l'équation de Wald se base sur le concept que $S_n = \sum_{i=1}^{N(t)} T_i$, très semblable au modèle fréquence-sévérité.},
\[\esp{S_{N(t) + 1}} = \esp{T}(m(t) + 1)\]

\subsection*{Variables}

\begin{enumerate}
	\item[Âge:]	$A(t) = t - S_{N(t)}$, temps à $t$ depuis le dernier renouvellement.
	\item[Temps de vie résiduel:]	$Y(t) = S_{N(t) + 1} - t$, temps à $t$ jusqu'au prochain renouvellement.
	\item[Temps de vie total:]	$V(t) = S_{N(t) + 1} - S_{N(t)} = A(t) + Y(t)$
\end{enumerate}

\subsection*{Key renewal theorem}
\[\lim_{t \to \infty} \int_{0}^{t} h(t-x) d m(x) = \frac{1}{\esp{T}} \int_{0}^{\infty} h(x) dx \]

\subsection*{Processus de renouvellement avec délai}
\begin{itemize}
\item Soit $\{ T_n : n \in \naturels \}$ des temps entre des renouvellements succesifs qui sont \emph{iid} tel que $F_{T_n}(t) = F_{T_2}(t)$ pour $n \geq 2$ et $F_{T_1(t)} \neq F_{T_2}(t)$. Alors $\{N_d(t) ; t \geq 0 \}$ est dit être un processus de renouvellement avec délai. 

\item La distribution de $N_d(t)$ est
\[\prob{N_d(t) = n} = F_{T_1} \ast F_{T_2}^{\ast(n-1)}(t) - F_{T_1} \ast F_{T_2}^{\ast (n)}(t)  \]

\item la fonction de renouvellement $m_d(t)$ est donc
\[m_d(t) = \sum_{n=1}^{\infty} F_{T_1} \ast F_{T_2}^{\ast (n-1)}(t)  \]

\item De plus, $m_d(t)$ satisfait aussi l'équation de renouvellement, telle que
\[m_d(t) = F_{T_1}(t) + \int_{0}^{t}  m_o(t-x) f_{T_1}(x) dx \]
où $m_o(t)$ est la fonction de renouvellement d'un processus de renouvellement ordinaire qui débute à $T_2$.
\end{itemize}

\subsection*{Processus de renouvellement \emph{stationnaire}}
\begin{itemize}
\item Un processus de renouvellement $\{ N_e(t) ; t \geq 0 \}$ est dit stationnaire si
\[F_{T_1} = F_e(t) = \frac{\int_{0}^{t} \overline{F}_{T_2}(x) dx  }{\esp{T_2}}\]

\item La fonction de renouvellement $m_e(t)$ est définie par
\[m_e(t) = \esp{N_e(t)} = \frac{t}{\esp{T_2}} \]

\item La distribution de $N_e(t)$ est définie par
\[\prob{N_e(t+h) - N_e(t) = n} = \prob{N_e(h) = n}\]
Car les accroissements sont stationnaires.
\end{itemize}

\subsection*{Processus de renouvellement alterné}
\begin{itemize}
\item Soit la suite $\{ (T_n, T_n') ; n \in \naturels \}$ des vecteurs \emph{iid} où les composantes $(T_n, T_n')$ peuvent être dépendantes. $T_n$ représente un intervalle de temps dans lequel le processus (de renouvellement) est \emph{on} et $T_n'$ un intervalle de temps où le processus est \emph{off}.

\item On peut donc définir 2 processus  (\emph{on} et \emph{off}) :  
\begin{itemize}
	\item $\{ N_1(t) ; t \geq 0 \}$ est un processus de renouvellement \emph{avec délai} généré par la suite des temps $\{ T_1, T_n' + T_{n+1} ; n \in \entiers \}$, et sa fonction de renouvellement est
	\begin{align*}
	m_1(t) & = \sum_{n=1}^{\infty} F_{T_1} \ast F_{T_2 + T_1'}
	^{\ast(n-1)}(t) \\
	& = \sum_{n=1}^{\infty} F_{T_1}^{\ast(n)}(t) \ast F_{T_1'}^{\ast(n-1)}(t) \\
	\end{align*}
	\item 	$\{ N_2(t) ; t \geq 0 \}$ est un processus de renouvellement \emph{ordinaire} généré par la suite des temps $\{ T_n + T_n'; n \in \entiers \}$, et sa fonction de renouvellement est
	\begin{align*}
	m_2(t) &= \sum_{n=1}^{\infty} F_{T_1 +  T_1'}^{\ast(n)}(t) = \sum_{n=1}^{\infty} F_{T_1}^{\ast(n)} \ast F_{T_1'}^{\ast(n)}(t) \\
	\end{align*}
\end{itemize}
\item \textbf{Proposition 1 : } Supposons que $T_n$ est indépendant de $T_n'$, $\forall n \in \naturels$ et soit $p_i(t)$ la probabilité que le processus de renouvellement alterné soit dans l'état $i$ au temps $t$, $i=1,2$. Alors,
\[p_1(t) = m_2(t) - m_1(t) + 1 = 1 - p_2(t) \]

\item \textbf{Proposition 2 : } Avec les mêmes hypothèses qu'à la proposition 1, on a
\[\lim_{t \to \infty} p_1(t) = \frac{\esp{T_1}}{\esp{T_1} + \esp{T_1'}} = 1 - \lim_{t \to \infty} p_2(t) \]
\end{itemize}

\subsection*{Application : somme de renouvellements avec réclamations escomptées}
\begin{itemize}
\item On considère le processus des réclamations escomptées à $t=0$, soit $\{ Z(t) ; t \geq 0 \}$, défini par
\[Z(t) = \sum_{k=1}^{N(t)} e^{-\delta S_k} X_k  \]
où
\begin{itemize}
	\item $\{N(t) ; t \geq 0 \}$ un processus de renouvellement ordinaire ;
	\item $S_k$ est le moment où se produit la $k$\up{e} réclamation ;
	\item La suite $\{ X_n ; n \in \entiers \}$ de v.a. \emph{iid} et indépendantes de $N(t)$ représentant les montants de réclamations ;
	\item $\delta$ est la force d'intérêt appliquée pour actualiser les réclamations.
\end{itemize}

\item Dans un processus de renouvellement ordinaire, on a, pour $k = 1, 2, ..., n$,
\begin{align*}
f_{S_k | N(t)}(x | n) = f_{S_k}(x) \frac{\prob{N(t-x) = n-k}}{\prob{N(t) = n}}
\end{align*}

\item On peut calculer le premier moment du processus des réclamations escomptées $\{ Z(t) ; t \geq 0 \}$ : 
\[\esp{Z(t)} = \esp{X} \int_{0}^{t} e^{-\delta x} d m(x) \]
où $m(t)$ est la fonction de renouvellement du processus de renouvellement $\{ N(t) ; t \geq 0 \}$.
\end{itemize}

\subsection*{Renewal Reward Processes}

Soit:
\begin{itemize}
	\item	$\{N(t), t \ge 0\}$ un processus de renouvellement avec
	\item	$X_{n}$ le temps inter-arrivées.
\end{itemize}
On suppose qu'à chaque renouvellement, nous recevons une 
\begin{itemize}
	\item	$R_{n}$ \textit{reward} que nous supposons être iid;
\end{itemize}
Cependant, il est possible, voir probable, que la reward $R_{n}$ dépend de la longueur de l'intervalle $X_{n}$.

Tout comme 
\begin{itemize}
	\item	pour $X_{n}$ on défini $S_{N(t)} = \sum_{n = 1}^{N(t)}$, 
	\item	on défini le total earned reward à, ou avant, le temps t $R(t) = \sum_{n = 1}^{N(t)} R_{n}$.
\end{itemize}

De plus on pose $\text{E}[R] = \text{E}[R_{n}]$ et $\text{E}[X] = \text{E}[X_{n}]$.

On obtient alors que 
\begin{definition}[Définition]
\begin{align*}
	\underset{t \rightarrow \infty}{\lim} \frac{R(t)}{t}	
	&=	\underset{t \rightarrow \infty}{\lim} \frac{\text{E}[R(t)]}{t}	&
	&=	\frac{\text{E}[R]}{\text{E}[X]}	&
	&=	\frac{\text{E}[\text{reward during a cycle}]}{\text{E}[\text{length of a cycle}]}
\end{align*}
\end{definition}



\section{Mouvement Brownien}
\subsection*{Définitions}
\begin{definition}[Définition générale]
Un processus stochastique $\{ X(t) ; t \geq 0 \}$ est dit être un mouvement Brownien \emph{avec paramètre de variance} $\sigma^2$ si
\begin{enumerate}[label=(\arabic*)]
\item $X(0) = 0$ ;
\item $\{ X(t) ; t \geq 0 \}$  a des accroissements indépendants et stationnaires ;
\item $\forall t > 0$, $X(t) \sim \mathcal{N}(0, \sigma^2 t)$.
\end{enumerate}
\end{definition}
Note : on appelle aussi $\sigma$ le \emph{paramètre de volatilité} ou \emph{coefficient de diffusion}. Un mouvement Brownien est dit \emph{standard} si $\sigma = 1$.

\subsubsection*{Proposition 1}
Considérons un mouvement Brownien standard. Alors, $\forall 0 < t_1 < t_2 < ... < t_{n}$, on a
\begin{align*}
f_{X_1(t_1), ..., X_n(t_n)}(x_1, ..., x_n) = \frac{e^{-\frac{1}{2} \left(\frac{x_1^2}{t_1} + \frac{(x_2 - x_1)^2}{t_2 - t_1} + ... + \frac{(x_n - x_{n-1})^2}{t_n - t_{n-1}} \right)}}{(2 \pi)^{\frac{n}{2}} (t_1 (t_2 - t_2) ... (t_n - t_{n-1}))^{\frac{1}{2}}} 
\end{align*}

\subsubsection*{Proposition 2}
Considérons un mouvement Brownien standard. Alors, $\forall 0 < s < t$, $X(s) | X(t)$ obéit à une loi normale, tel que
\begin{align*}
\esp{X(s) | X(t) = x}&  = \frac{s}{t} x \\
\variance{X(s) |X(t) = x} & = \frac{s}{t} \left( t - s \right) \\
\end{align*}

\subsection*{Temps d'atteinte d'une barrière}
\begin{itemize}
\item Soit $T_a$ le le premier moment où le mouvement Brownien standard atteint le niveau $a$. Alors,
\[\prob{T_a \leq t} = \sqrt{\frac{2}{\pi}} \int_{|a| / \sqrt{t}}^{\infty} e^{- \frac{x^2}{2}} dx   \]

\item On peut trouver la distribution de la valeur maximale que peut prendre $\{ X(s) ; 0 \leq s \leq t \}$, telle que
\[\prob{\max_{0 \leq s \leq t} X(s) \geq a} =  \sqrt{\frac{2}{\pi}} \int_{a / \sqrt{t}}^{\infty} e^{- \frac{x^2}{2}} dx\]
\end{itemize}


\subsection*{Variations sur le mouvement Brownien}
\subsubsection*{Mouvement Brownien avec dérive}
Un mouvement Brownien avec dérive (\emph{drifted}) a exactement la même définition qu'un mouvement Brownien standar, à l'exception que
\[X(t) \sim \mathcal{N} \left(\mu t, \sigma^2 t \right) \]
où $\mu$ est le \emph{paramètre de dérive}.\\
 Note : on a donc que $X(t) = \mu t + \sigma B(t)$, où $B(t)$ est un mouvement Brownien standard.

\subsubsection*{Mouvement Brownien géométrique}
\begin{definition}[Définition]
Soit $\{X(t) ; t \geq 0 \}$ un mouvement Brownien brownien avec dérive $\mu$ et volatilité $\sigma$. Alors, le processus $\{X(t) ; t \geq 0 \}$ défini par
\[X(t) = e^{Y(t)}\]
est dit être un mouvement Brownien \emph{géométrique}.
\end{definition}
\textbf{Proposition : } Soit $\{X(t) ; t \geq 0 \}$ un mouvement Brownien géométrique avec dérive $\mu$ et volatilité $\sigma$. Alors,
\[\esp{X(t) | X(u)} = X(s) e^{(t-s) \left(\mu + \frac{\sigma^2}{2} \right)} \]
pour $ 0 \leq u \leq s \leq t$.

\subsubsection*{Pont Brownien}
\begin{definition}[Processus Gaussien]
Un processus stochastique $\{X(t) ; t \geq 0 \}$ est dit être un processus Gaussien si, $\forall 0 < t_1 < t_2 < ... < t_n$, $X(t_1), ..., X(t_n)$ a une distribution normale multivariée.
\end{definition}

\begin{definition}[Définition alternative d'un mouvement Brownien standard]
Un processus $\{X(t) ; t \geq 0 \}$ est un mouvement Brownien standard ssi
\begin{enumerate}[label=(\arabic*)]
\item $\{X(t) ; t \geq 0 \}$ est un processus Gaussien ;
\item $\forall t > 0$, $\esp{X(t)} = 0$, avec $X(0) = 0$ ;
\item $\forall 0 \leq s \leq t$, on a $\covar{X(s), X(t)} = s$.
\end{enumerate}
\end{definition}

\begin{definition}[Définition d'un pont Brownien]
Soit $\{X(t) ; t \geq 0 \}$ un mouvement Brownien standard. Alors, le processus conditionnel $\{X(t) ; 0 \leq t \leq 1 | X(1) = 0 \}$ est dit être un \emph{pont} Brownien.  De plus, on a
\begin{align*}
\esp{X(t) | X(1) = 0} & = 0 \\
\shortintertext{Et, pour $s < t < 1$,} \\
\covar{X(s), X(t) | X(1) = 0} & = s(1-t). \\
\end{align*}
\end{definition}
Une autre condition pour déterminer si le processus $\{ Z(t) ; t \geq 0 \}$ est un point Brownien est de vérifier que l'équation suivante est respectée : 
\[Z(t) = X(t) - t X(1) \]

\subsection*{Mouvement Brownien intégré}
\begin{definition}[Définition de l'Intégrale d'Îto]
Soit $\{X(t) ; t \geq 0 \}$ un mouvement Brownien standard et une fonction $f$ est une dérivée continue. Alors, nous définissons \emph{l'intégrale stochastique d'Îto} comme \\
$\int_{a}^{b} f(t) d X(t) = f(b) X(b) - f(a) X(a) - \int_{a}^{b} X(t) d f(t)$
\end{definition}

\begin{definition}[Définition du mouvement Brownien intégré]
Si $\{X(t) ; t \geq 0 \}$ un mouvement Brownien standard, alors le processus Soit $\{Z(t) ; t \geq 0 \}$ défini par (en utilisant \emph{l'intégrale d'Îto)}
\[Z(t) = \int_{0}^{t} X(s) ds = t X(t) - \int_{0}^{t} v \cdot  d X(v) \]
\end{definition}


\subsubsection*{Proposition 2}
L'espérance et la variance de $\int_{a}^{b} f(t) d X(t) $ sont respectivement
\begin{align*}
\esp{\int_{a}^{b} f(t) d X(t) } & = 0 \\
\variance{\int_{a}^{b} f(t) d X(t)  } & =  \int_{a}^{b} f(t)^2 dt \\
\end{align*}


\subsubsection*{Proposition 3}
La mouvement Brownien intégré (tout comme le mouvement Brownien standard) obéit à une loi Normale. En combinant avec les hypothèses de la proposition 2, on a
\begin{align*}
\int_{a}^{b} f(t) d X(t) \sim \mathcal{N} \left( 0 , \int_{a}^{b} f(t)^2 dt \right)
\end{align*}
et
\begin{align*}
\int_{a}^{b} X(t) d f(t) \sim \mathcal{N} \left( 0, a\left(f(b) - f(a)\right)^2 + \int_{a}^{b} \left( f(b) - f(t) \right)^2 dt \right)
\end{align*}





\end{multicols*}

%% -----------------------------
%% Fin du document
%% -----------------------------
\end{document}